Renderer: llvmpipe (LLVM 20.1.2, 256 bits) by Mesa
OpenGL version: 4.5 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2
Using optional features:
    GL_ARB_vertex_array_object
    GL_ARB_ES2_compatibility
    GL_ARB_separate_shader_objects
    GL_ARB_robustness
    GL_ARB_texture_storage
    GL_ARB_texture_view
    GL_ARB_framebuffer_no_attachments
    GL_ARB_invalidate_subdata
    GL_ARB_texture_storage_multisample
    GL_ARB_multi_bind
    GL_ARB_direct_state_access
    GL_ARB_get_texture_sub_image
    GL_ARB_texture_filter_anisotropic
    GL_KHR_debug
    GL_KHR_parallel_shader_compile
Using driver workarounds:
    no-layout-qualifiers-on-old-glsl
    mesa-implementation-color-read-format-dsa-explicit-binding
    mesa-dsa-createquery-except-pipeline-stats
    mesa-forward-compatible-line-width-range
[DEBUG] Current script: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/run_navigation_experiments.py
[DEBUG] Added to path: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments
âœ… METRICS: Initialized trajectory tracker
âœ… METRICS: Initialized collisions tracker = 0
âœ… METRICS: Initialized start_time tracker
ğŸ¯ HabitatStore initialized - Thread-safe simulator access
ğŸ”§ OFFLINE MODE: Using cached OWL-ViT (no internet needed)
ğŸ”§ Running from: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main
ğŸ”§ MAIN_DIR: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/policies
ğŸ”§ Python path: ['/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/policies', '/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments', '/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments', '/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/build/python_module', '/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/ORB_SLAM3', '/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main', '/home/kalya/miniconda3/envs/robotics_base/lib/python39.zip', '/home/kalya/miniconda3/envs/robotics_base/lib/python3.9', '/home/kalya/miniconda3/envs/robotics_base/lib/python3.9/lib-dynload', '/home/kalya/miniconda3/envs/robotics_base/lib/python3.9/site-packages', '/home/kalya/miniconda3/envs/robotics_base/lib/python3.9/site-packages/habitat_sim-0.3.3-py3.9-linux-x86_64.egg', '/home/kalya/miniconda3/envs/robotics_base/lib/python3.9/site-packages/pillow-10.4.0-py3.9-linux-x86_64.egg']
ğŸ¯ Initializing DEADLOCK-FREE Frame Buffer: 64 frames
âœ… DEADLOCK-FREE RGB-D Buffer Ready: 64 frames, 93.8 MB
   RGB: (480, 640, 3), Depth: (480, 640)
   Memory layout: RGB=58982400 bytes, Depth=39321600 bytes
[DEBUG] âœ… ALL policies imported successfully!
[DEBUG] Imported all policy entrypoints
[DEBUG] Registered policies: ['ours_full']
[DEBUG] __main__ entry point
[DEBUG] Starting SINGLE episode run
[DEBUG] Loading evaluation_episodes.json
[DEBUG] Looking for JSON at: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/evaluation_episodes.json
[DEBUG] Loaded 250 episodes
ğŸ¯ SINGLE EPISODE: 00800_tv_005
ğŸƒ RUNNING ALL POLICIES: ['ours_full']

============================================================
ğŸš€ RUNNING POLICY: ours_full
============================================================
ğŸš€ OursFull: 00800_tv_005
ğŸ“‹ DEBUG: Episode keys = ['episode_id', 'scene_path', 'start_pose', 'goal', 'success_radius', 'max_steps', 'seed']
ğŸ“ Frame save directory: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005
âš™ï¸  DEBUG: Config created = {'num_frames': 500, 'scene_path': 'projects/hybrid_zero_shot_slam_nav/main/datasets/00800-TEEsavR23oF/TEEsavR23oF.basis.glb', 'frame_save_dir': '/mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005'}
ğŸ­ DEBUG: Creating OursFullPolicy...
ğŸ“ Frame save directory configured: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005
Central Map Store initialized
âœ… Task Store initialized - Pure task management
ğŸ”„ Creating HM3D environment with direct GLB loading...
ğŸ”„ Loading scene from: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/datasets/00800-TEEsavR23oF/TEEsavR23oF.basis.glb
Agent config: AgentConfiguration(height=1.0, radius=0.18, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba592c0>, <habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba59310>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder')
Action space: ['move_forward', 'turn_left', 'turn_right']
âœ… HM3D Scene Loaded Successfully!

ğŸ” === SEMANTIC MESH DEBUG (OURS_FULL) ===
[DEBUG] cfg.load_semantic_mesh = True
[DEBUG] sim.semantic_scene is None? False
[DEBUG] semantic objects count = 661
[DEBUG] FIRST 10 SEMANTIC OBJECTS:
  0: 'Unknown'
  1: 'ceiling'
  2: 'wall'
  3: 'wall'
  4: 'door'
  5: 'handle'
  6: 'wall'
  7: 'wall'
  8: 'chandelier'
  9: 'wardrobe'
[DEBUG] scene_dataset_config_file exists: True
ğŸ” === END SEMANTIC DEBUG ===

ğŸ“· Camera intrinsics extracted & stored:
{'fx': 320.00000000000006, 'fy': 320.00000000000006, 'cx': 320.0, 'cy': 240.0, 'width': 640, 'height': 480, 'hfov_deg': 90.0}
ğŸ”„ Loading navmesh: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/datasets/00800-TEEsavR23oF/TEEsavR23oF.basis.navmesh
âœ… NavMesh loaded: True
ğŸ”¥ === LOCOBOT ROBOT (Your Assets) ===
ğŸ”§ ROBOT CREATED: friction=roll1.0,spin1.0
âœ… LOCOBOT ID=1 | Agent embodied!
ğŸ”¥ === FULL ROBOT PHYSICS READY ===
ğŸ” Test sensors available: ['rgba_camera', 'depth_camera']
 (640, 480, 4) | dtype: uint8
âœ… Depth: (640, 480) | dtype: float32
ğŸ“· RGB: HFOV=Deg(90)Â°, Resolution=Vector(640, 480)
ğŸ“· Depth: HFOV=Deg(90)Â°, Resolution=Vector(640, 480)

ORB-SLAM3 Copyright (C) 2017-2020 Carlos Campos, Richard Elvira, Juan J. GÃ³mez, JosÃ© M.M. Montiel and Juan D. TardÃ³s, University of Zaragoza.
ORB-SLAM2 Copyright (C) 2014-2016 RaÃºl Mur-Artal, JosÃ© M.M. Montiel and Juan D. TardÃ³s, University of Zaragoza.
This program comes with ABSOLUTELY NO WARRANTY;
This is free software, and you are welcome to redistribute it
under certain conditions. See LICENSE.txt.

Input sensor was set to: RGB-D
Loading settings from /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/../../configs/slam/orb_slam3_config.yaml
	-Loaded camera 1
	-Loaded image info
	-Loaded RGB-D calibration
	-Loaded ORB settings
	-Loaded viewer settings
	-Loaded Atlas settings
	-Loaded misc parameters
----------------------------------
SLAM settings: 
	-Camera 1 parameters (Pinhole): [ 320 320 320 240 ]
	-Camera 1 distortion parameters: [  0 0 0 0 0 ]
	-Original image size: [ 640 , 480 ]
	-Current image size: [ 640 , 480 ]
	-Sequence FPS: 30
	-RGB-D depth map factor: 1
	-Features per image: 1000
	-ORB scale factor: 1.2
	-ORB number of scales: 8
	-Initial FAST threshold: 20
	-Min FAST threshold: 7


Loading ORB Vocabulary. This could take a while...
Vocabulary loaded!

Initialization of Atlas from scratch 
Creation of new map with id: 0
Creation of new map with last KF id: 0
Seq. Name: 
There are 1 cameras in the atlas
Camera 0 is pinhole
checking self.env instance for habitat sim  inside create hm3d habitat env function Simulator(config=Configuration(sim_cfg=<habitat_sim._ext.habitat_sim_bindings.SimulatorConfiguration object at 0x7202bc574e70>, agents=[AgentConfiguration(height=1.0, radius=0.18, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba592c0>, <habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba59310>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder'), AgentConfiguration(height=1.5, radius=0.1, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba593b0>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder')], metadata_mediator=None, enable_batch_renderer=False), agents=[Agent(agent_config=AgentConfiguration(height=1.0, radius=0.18, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba592c0>, <habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba59310>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder'), _sensors={'rgba_camera': <habitat_sim._ext.habitat_sim_bindings.CameraSensor object at 0x7202bba58d70>, 'depth_camera': <habitat_sim._ext.habitat_sim_bindings.CameraSensor object at 0x7202bba58df0>}, controls=ObjectControls(move_filter_fn=<bound method Simulator.step_filter of ...>), body=<_magnum.scenegraph.AbstractFeature3D object at 0x7202bba58c70>), Agent(agent_config=AgentConfiguration(height=1.5, radius=0.1, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba593b0>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder'), _sensors={'third_rgb': <habitat_sim._ext.habitat_sim_bindings.CameraSensor object at 0x7202bba58f70>}, controls=ObjectControls(move_filter_fn=<bound method Simulator.step_filter of ...>), body=<_magnum.scenegraph.AbstractFeature3D object at 0x7202bba58d30>)], _num_total_frames=0, _default_agent_id=0, _Simulator__sensors=[{'rgba_camera': <habitat_sim.simulator.Sensor object at 0x7202bc42eb80>, 'depth_camera': <habitat_sim.simulator.Sensor object at 0x7202bc42ebb0>}, {'third_rgb': <habitat_sim.simulator.Sensor object at 0x7202bc42ed60>}], _initialized=True, _previous_step_time=0.0, _async_draw_agent_ids=None, _Simulator__last_state={0: AgentState(position=array([-9.448947  ,  0.16337794, -1.182925  ], dtype=float32), rotation=quaternion(1, 0, 2.45858027483337e-05, 0), sensor_states={'rgba_camera': SixDOFPose(position=array([-9.448947,  1.163378, -1.182925], dtype=float32), rotation=quaternion(1, 0, 2.45858027483337e-05, 0)), 'depth_camera': SixDOFPose(position=array([-9.448947,  1.163378, -1.182925], dtype=float32), rotation=quaternion(1, 0, 2.45858027483337e-05, 0))}), 1: AgentState(position=array([-4.013434,  3.163378, -7.512126], dtype=float32), rotation=quaternion(0.915825247764587, 0, 0.401577025651932, 0), sensor_states={'third_rgb': SixDOFPose(position=array([-4.013434,  4.663378, -7.512126], dtype=float32), rotation=quaternion(0.915825247764587, 0, 0.401577025651932, 0))})})
âœ… Simulator stored 
Occupancy grid: 50x50 cells, 0.05m resolution
ORBSLAMIntegration instance created
Initializing ORB-SLAM3 system...
ğŸ”„ ORB-SLAM: Starting initialization...
ğŸ“ ORB-SLAM: Config path: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/configs/slam/orb_slam3_config.yaml
ğŸ“ ORB-SLAM: Vocab path: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/ORB_SLAM3/Vocabulary/ORBvoc.txt
Looking for config at: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/configs/slam/orb_slam3_config.yaml
Looking for vocab at: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/ORB_SLAM3/Vocabulary/ORBvoc.txt
Config file size: 758 bytes
Vocab file size: 145250924 bytes
Creating ORB-SLAM3 System instance for RGB-D...
ORB-SLAM3 RGB-D initialized and processing started
âœ… ORB-SLAM: Successfully initialized!
ğŸ¦‰ OWLIntegration created - Consumer only (reads from global buffer)
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWLIntegration created - Consumer only (reads from global buffer)
ğŸ“¢ PredictionStore: New subscriber added. Total: 1
Integrated ReasoningPipeline instance created
ğŸ”® IjepaPredictor: Loading prototypes directly from JSON...
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
âœ… free_space: shape torch.Size([1, 1280])
âœ… Loaded 1 centroids
ğŸ”® IjepaPredictor: Starting I-JEPA initialization...
ğŸ”® IjepaPredictor: Loading model facebook/ijepa_vith14_1k...
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [0. 0. 0.]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [0. 0. 0.]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ”® IjepaPredictor: âœ… Model loaded successfully via transformers
ğŸ”® IjepaPredictor: âœ… I-JEPA fully initialized with transformers!
ğŸš€ Action Executor initialized - Continuous Navigation Built-in
TaskStore[125360300869040] new subscriber â†’ <bound method ActionPipeline.on_action_plan_ready of <experiments.paper_experiments.Main_Experiments.policies.ours_full.run_ours_full_action_pipeline.ActionPipeline object at 0x7202bba68220>>
ğŸ›ï¸ Main Orchestrator - ORB-SLAM created, simulator ready
âœ… DEBUG: Orchestrator created = <experiments.paper_experiments.Main_Experiments.policies.ours_full.ours_full_policy.OursFullPolicy object at 0x720396bd8fa0>
ğŸ¯ DEBUG: Setting episode start pose...
ğŸ‘¤ DEBUG: Agent 0 acquired
ğŸ“ DEBUG: Current state = pos:[0. 0. 0.], rot:quaternion(1, 0, 0, 0)
ğŸ“ DEBUG: Set position = [-0.14  1.   -2.52]
ğŸ”„ DEBUG: Yaw = 2.5
ğŸ”„ DEBUG: New rotation quat = [0.         0.94898462 0.         0.31532236]
âœ… DEBUG: Start pose applied!
ğŸ’¾ DEBUG: initial_pose set in HabitatStore: {'position': [-0.14000000059604645, 1.0, -2.5199999809265137], 'rotation': quaternion(0.315322362395269, 0, 0.948984619355586, 0)}
ğŸ” DEBUG: Searching for goal object...
ğŸ¯ DEBUG: Target category = 'tv'
ğŸ“Š DEBUG: Found 661 semantic objects
  ğŸ” Obj 0: 'Unknown'
  ğŸ” Obj 1: 'ceiling'
  ğŸ” Obj 2: 'wall'
  ğŸ” Obj 3: 'wall'
  ğŸ” Obj 4: 'door'
  ğŸ” Obj 5: 'handle'
  ğŸ” Obj 6: 'wall'
  ğŸ” Obj 7: 'wall'
  ğŸ” Obj 8: 'chandelier'
  ğŸ” Obj 9: 'wardrobe'
  ğŸ” Obj 10: 'tv'
âœ… DEBUG: GOAL FOUND! pos = [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
ğŸ’¾ DEBUG: Goal stored to HabitatStore: tv at [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
ğŸ¯ DEBUG: Final goal_pos = [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
ğŸš€ DEBUG: Starting orchestration...
ğŸš€ Starting main orchestration for task: find tv
checking self.env instance for habitat sim inside run_orchestration function Simulator(config=Configuration(sim_cfg=<habitat_sim._ext.habitat_sim_bindings.SimulatorConfiguration object at 0x7202bc574e70>, agents=[AgentConfiguration(height=1.0, radius=0.18, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba592c0>, <habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba59310>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder'), AgentConfiguration(height=1.5, radius=0.1, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba593b0>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder')], metadata_mediator=None, enable_batch_renderer=False), agents=[Agent(agent_config=AgentConfiguration(height=1.0, radius=0.18, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba592c0>, <habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba59310>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder'), _sensors={'rgba_camera': <habitat_sim._ext.habitat_sim_bindings.CameraSensor object at 0x7202bba58d70>, 'depth_camera': <habitat_sim._ext.habitat_sim_bindings.CameraSensor object at 0x7202bba58df0>}, controls=ObjectControls(move_filter_fn=<bound method Simulator.step_filter of ...>), body=<_magnum.scenegraph.AbstractFeature3D object at 0x7202bba58c70>), Agent(agent_config=AgentConfiguration(height=1.5, radius=0.1, sensor_specifications=[<habitat_sim._ext.habitat_sim_bindings.CameraSensorSpec object at 0x7202bba593b0>], action_space={'move_forward': ActionSpec(name='move_forward', actuation=ActuationSpec(amount=0.25, constraint=None)), 'turn_left': ActionSpec(name='turn_left', actuation=ActuationSpec(amount=10.0, constraint=None)), 'turn_right': ActionSpec(name='turn_right', actuation=ActuationSpec(amount=10.0, constraint=None))}, body_type='cylinder'), _sensors={'third_rgb': <habitat_sim._ext.habitat_sim_bindings.CameraSensor object at 0x7202bba58f70>}, controls=ObjectControls(move_filter_fn=<bound method Simulator.step_filter of ...>), body=<_magnum.scenegraph.AbstractFeature3D object at 0x7202bba58d30>)], _num_total_frames=0, _default_agent_id=0, _Simulator__sensors=[{'rgba_camera': <habitat_sim.simulator.Sensor object at 0x7202bc42eb80>, 'depth_camera': <habitat_sim.simulator.Sensor object at 0x7202bc42ebb0>}, {'third_rgb': <habitat_sim.simulator.Sensor object at 0x7202bc42ed60>}], _initialized=True, _previous_step_time=0.0, _async_draw_agent_ids=None, _Simulator__last_state={0: AgentState(position=array([-9.448947  ,  0.16337794, -1.182925  ], dtype=float32), rotation=quaternion(1, 0, 2.45858027483337e-05, 0), sensor_states={'rgba_camera': SixDOFPose(position=array([-9.448947,  1.163378, -1.182925], dtype=float32), rotation=quaternion(1, 0, 2.45858027483337e-05, 0)), 'depth_camera': SixDOFPose(position=array([-9.448947,  1.163378, -1.182925], dtype=float32), rotation=quaternion(1, 0, 2.45858027483337e-05, 0))}), 1: AgentState(position=array([-4.013434,  3.163378, -7.512126], dtype=float32), rotation=quaternion(0.915825247764587, 0, 0.401577025651932, 0), sensor_states={'third_rgb': SixDOFPose(position=array([-4.013434,  4.663378, -7.512126], dtype=float32), rotation=quaternion(0.915825247764587, 0, 0.401577025651932, 0))})})
ğŸ“ METRICS: START POS = [-0.14  1.   -2.52]
ğŸ“ METRICS: Trajectory len = 1
â±ï¸  METRICS: Start time recorded
ğŸ¯ Processing limit: 500 frames
ğŸ¯ Mission goals set: ['tv']
ğŸ“‹ Added task: explore - Explore unknown area
ğŸ¯ Initial task set: find tv
âœ… Created task: find tv
ğŸ“‹ Complete reasoning plan stored with ID: reason_1767143847273
ğŸ“Š Action plan has 2 waypoints
ğŸ“ Also stored in intermediate_reasoning for OWL access
ğŸ”„ Starting pipeline processing...
Initializing OWL integration...
Loading OWL-ViT model: google/owlvit-base-patch32
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
âœ… OWL-ViT model loaded successfully
ğŸ” OWL Model device after loading: cuda:0
ğŸ¦‰ OWL DEBUG: Model loaded successfully - ready for frame buffer processing
âœ… OWL integration ready - Processing every 3 frames from buffer
ğŸŸ¢ OWL continuous processing loop started
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: Started continuous processing
Initializing integrated reasoning pipeline...
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
Spatial Reasoning Integration initialized - Stores available: True
âœ… Spatial Reasoning Integration initialized
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¯ LLM DEBUG: Starting to load TinyLlama/TinyLlama-1.1B-Chat-v1.0
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14  1.   -2.52]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14  1.   -2.52]
ğŸ” MOTION CHECK: âœ… First frame, will process
First KF:0; Map init KF:0
New Map created with 843 points
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ BUFFER DEBUG: Frame ID requested: -1
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame -1 
âœ… LLM DEBUG: Pipeline loaded successfully on cpu
ğŸŒ³ Tree of Thoughts Integration initialized with LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0
   ğŸ“ Map Store: âœ…
   ğŸ¯ User Command Store: âœ…
   ğŸ“Š Prediction Store: âœ…
   ğŸ“ Task Store: âœ…
âœ… Tree of Thoughts Integration initialized
ğŸ”§ INITIALIZATION DEBUG:
   Spatial Reasoning: True
   Tree of Thoughts: True
âœ… Integrated reasoning pipeline initialized successfully
   global_habitat_store imported: True
âœ… Exploration budget exhausted, returning control
âœ… All pipelines started successfully
ğŸ”„ Stepping simulator 3 times to warm up sensors...
DEBUG: about to step simulator
ğŸ¦‰ OWL: starting to Process REAL frame -1 
âœ… Simulator warm-up complete, first frames ready
ğŸ”„ Stepping simulator 3 times to warm up sensors...
DEBUG: about to step simulator
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
âœ… Simulator warm-up complete, first frames ready
ğŸ”„ Stepping simulator 3 times to warm up sensors...
DEBUG: about to step simulator
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
âœ… Simulator warm-up complete, first frames ready
ğŸ” Mission check: 1 total goals, 1 remaining
   Mission goals: {'tv'}
   Remaining goals: ['tv']

--- FRAME 1/500 ---
DEBUG: about to get sensor observations
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¦‰ OWL: starting to Process REAL frame -1 
ğŸ¯ CURRENT SENSORS: ['rgba_camera', 'depth_camera']
DEBUG: about to extract rgb and depth
ğŸ¯ DEPTH STATS - Min: 0.5622655153274536, Max: 2.366044521331787, Mean: 1.080
âœ… Depth frame has 307200 valid pixels
DEBUG: RGBA -> RGB conversion for frame 0
DEBUG: Transposing rgb_frame from (640, 480, 3) to (480, 640, 3)
DEBUG: Depth frame shape before transpose: (640, 480)
DEBUG: Depth frame shape after transpose: (480, 640)
DEBUG: Converted depth dtype to uint16
DEBUG: about to rotate rgb frame
DEBUG: about to scale depth
ğŸ¯ DEBUG: Frame 0 - RGB shape: (480, 640, 3), Depth shape: (480, 640)
ğŸ¯ DEBUG: RGB dtype: uint8, Depth dtype: uint16
ğŸ¦‰ OWL: starting to Process REAL frame -1 
âœ… DEBUG: Frame 0 written to buffer - Slot 0
âœ… DEBUG: Buffer RGB dtype: uint8, Depth dtype: uint16
  Wrote frame 0 to buffer successfully âœ…
  âœ… Frame 1 captured - RGB: (480, 640, 3), Depth: (480, 640)
ğŸŸ¦ DEBUG: Calling ORB-SLAM process_frame() for frame 0
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: None
ğŸ”   last_processed_time: None
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK: âœ… First frame, will process
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'tuple'>
âœ… BUFFER DEBUG: Got frame_dict type: <class 'dict'>
âœ… BUFFER DEBUG: Got metadata type: <class 'dict'>
ğŸ¯ DEPTH SCALE CHECK: range=(562.0, 2366.0) dtype=uint16
âœ… ORB-SLAM: PROCESSED FRAME #1 (buffer ID: 0) - first_frame
   Current position: [-0.14        0.98967767 -2.52      ]
ğŸ”„ CONVERTING: Depth appears to be in millimeters
   Before: 562.0 to 2366.0 (uint16)
   After: 0.562m to 2.366m (float32)
ğŸ” DEPTH VALIDATION: 307200 valid pixels
ğŸ” RGB-D Frames: RGB=(480, 640, 3), Depth=(480, 640)
ğŸ” Depth info: dtype=float32, range=(0.562, 2.366)
ğŸ” DEBUG process_frame parameters:
   RGB: dtype=uint8, shape=(480, 640, 3)
   Depth: dtype=float32, shape=(480, 640)
   Timestamp: 0.0
ğŸ” ORB-SLAM RAW RESULT KEYS: ['current_pose', 'tracking_status', 'visible_points']
Current result dict pose : [[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]
ğŸ” ORB-SLAM INTERNAL DEBUG:
   Raw tracking_info keys: ['tracking_ok', 'tracking_lost', 'system_shutdown', 'visible_points_count']
   ğŸ“ tracking_ok: True
   ğŸ“ tracking_lost: False
   ğŸ“ system_shutdown: False
   ğŸ¯ TRACKING STATUS: âœ… TRACKING
   ğŸ¯ LOST STATUS: âœ… NOT LOST
ğŸ” FEATURE DEBUG:
   ğŸ‘ï¸ Visible points: 843
ğŸ¤– ORB-SLAM: Received valid 4x4 pose matrix
â³ Coordinates from orbslam Not aligned yet, storing SLAM-local pose
ğŸ“¦ Stored pose pair #1
   SLAM position: [[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]
   Habitat position: [[-0.80114363  0.          0.59847216 -0.14      ]
 [ 0.          1.          0.          0.98967767]
 [-0.59847216  0.         -0.80114363 -2.51999998]
 [ 0.          0.          0.          1.        ]]
ğŸ¯ STORE DEBUG - Frame 0:
   ğŸ“¦ Current pose type: <class 'numpy.ndarray'>
   ğŸ“¦ Pose shape: (4, 4)
   ğŸ“¦ Translation: [[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]
ğŸ—ºï¸ ORB-SLAM: 843 tracked points this frame
âœ… ORB-SLAM: Pose stored successfully
ğŸ“¦ Stored complete 4x4 pose matrix for frame 0
ğŸ¤– ORB-SLAM: Complete pose stored directly
ğŸ” Point conversion: 843 success, 843 rich points
ğŸ’¾ ORB-SLAM: Added 843 points to memory map
   ğŸ¯ Current Frame: 0
   ğŸ¤– Robot Position: [[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]
ğŸ’¾ ORB-SLAM: Frame 0 WORLD-ALIGNED data stored
ğŸ“Š ORB-SLAM FRAME 0 SUMMARY:
   Method: rgbd_processing
   Pose estimated: True
   Visible points: 843
   Tracking: OK
ğŸŸ© DEBUG: Returned from ORB-SLAM process_frame() for frame 0
ğŸ” Checking for queued actions...
ğŸ¯ HABITATSTORE: Pulling next action from queue
ğŸ“­ HABITATSTORE: Action queue is empty
ğŸ”® Running prediction cycle for frame 0...
ğŸ”® DEBUG: Starting prediction cycle for frame 0
ğŸ”® Prediction Cycle 0: Starting predictors...
ğŸ” DEBUG: Checking TaskStore.current_action_plan...
ğŸ” DEBUG: TaskStore has current_action_plan: True
âœ… Found task_id in task_context: reason_1767143847273
ğŸ“Š PredictionStore: Created entry pred_reason_1767143847273_1767143852369
âœ… Created prediction entry: pred_reason_1767143847273_1767143852369
ğŸ”® DEBUG: Prediction ID = pred_reason_1767143847273_1767143852369
ğŸ”® DEBUG: Calling collision predictor...
ğŸš§ CollisionRiskPredictor: Starting prediction...
  ğŸ“ Frame start time: 01:17:32
ğŸš§ CollisionRiskPredictor: Step 1 - Getting prediction ID...
ğŸš§ CollisionRiskPredictor: Prediction ID = pred_reason_1767143847273_1767143852369
ğŸš§ CollisionRiskPredictor: Step 2 - Fetching data from stores...
  ğŸ“ Robot position: [0.0, 0.0, 0.0]
  ğŸ“Š Semantic objects: 0 found
  ğŸ” Extracting ORB-SLAM map points...
  ğŸ“Š ORB-SLAM points: 0 points
  ğŸ¯ Planned actions: ['move_forward', 'turn_left', 'turn_right']
ğŸš§ CollisionRiskPredictor: Step 3 - Processing risks...
  ğŸ“ Computing immediate geometric risks...
    Immediate danger: False
    Closest obstacle: infm
    Risk score: 0.00
  ğŸ·ï¸ Computing semantic object risks...
    High risk zones: 0
    Medium risk zones: 0
  ğŸ¯ Calculating action-specific risks...
    Analyzing action: move_forward
      Base risk: 0.00
      Front risks: 0 â†’ Action risk: 0.00
      Final: risk_level=low, feasible=True, speed=normal
    Analyzing action: turn_left
      Base risk: 0.00
      Right risks: 0 â†’ Action risk: 0.00
      Final: risk_level=low, feasible=True, speed=normal
    Analyzing action: turn_right
      Base risk: 0.00
      Left risks: 0 â†’ Action risk: 0.00
      Final: risk_level=low, feasible=True, speed=normal
ğŸš§ CollisionRiskPredictor: Step 4 - Generating overall assessment...
  ğŸ“Š All risk scores: ['0.00', '0.00', '0.00']
  ğŸ“ˆ Max collision risk: 0.00
  ğŸ›¡ï¸ Safe navigation confidence: 1.00
  ğŸ¯ Overall risk level: low
ğŸš§ CollisionRiskPredictor: Step 5 - Building result...
ğŸš§ CollisionRiskPredictor: Step 6 - Saving to prediction store...
ğŸ“Š PredictionStore: Updated pred_reason_1767143847273_1767143852369 with collision_risk results
ğŸš§ CollisionRiskPredictor: âœ… Results stored successfully
ğŸ“Š PredictionStore: Updated pred_reason_1767143847273_1767143852369 with collision_risk results
âœ… CollisionRiskPredictor: Results stored in PredictionStore
ğŸš§ CollisionRiskPredictor: Prediction completed in 0.4ms

ğŸ“‹ PREDICTION SUMMARY:
   Prediction ID: pred_reason_1767143847273_1767143852369
   Overall risk: low
   Actions analyzed: ['move_forward', 'turn_left', 'turn_right']
   Processing time: 0.4ms
ğŸ”® DEBUG: Collision result type = <class 'dict'>
ğŸ”® DEBUG: Calling I-JEPA predictor...
ğŸ”® IjepaPredictor: Called with prediction_id=pred_reason_1767143847273_1767143852369
ğŸ”® IjepaPredictor: _execute_prediction_logic started
ğŸ”® DEBUG: prediction_id = pred_reason_1767143847273_1767143852369
ğŸ”® DEBUG: self.model available = True
ğŸ”® DEBUG: self.processor available = True
ğŸ”® DEBUG: prototypes loaded = 1
ğŸ”® IjepaPredictor: Getting frame from buffer
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 0.39s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â­ï¸ Skipping - trans=0.000m, rot=0.000rad, time=0.4s
ğŸ”   All below thresholds: trans<0.240, rot<0.100, time<1.0
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'

ğŸŸ¢ OWL DEBUG â”€â”€â”€ START FRAME 0 â”€â”€â”€
ğŸ“¦ Frame metadata:
   â€¢ frame_id      = 0
   â€¢ timestamp     = 0.0
   â€¢ rgb shape     = (480, 640, 3)
   â€¢ depth shape   = (480, 640)
ğŸ¯ Detection input: shape=(480, 640, 3), dtype=uint8
ğŸ” FRAME STATS:
   - Min pixel value: 0
   - Max pixel value: 243
   - Mean brightness: 142.2
   - Brightness std: 26.1
ğŸ¦‰ OWL DEBUG: Starting _get_text_queries_from_task_store
ğŸ¦‰ OWL DEBUG: self.task_store exists = True
ğŸ¯ OWL HABITATSTORE: Using stored goal 'tv'
ğŸ” CURRENT QUERIES DEBUG:
   - Query count: 1
   - First 3 queries: ['tv']
ğŸ” INPUTS DEBUG:
   - input_ids shape: torch.Size([1, 16])
   - attention_mask shape: torch.Size([1, 16])
   - pixel_values shape: torch.Size([1, 3, 768, 768])
   - pixel_values dtype: torch.float32
ğŸ” DEBUG: stack[1].function = get_latest_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/stores/frame_buffer.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='get_latest_frame [frame_buffer.py]', Model='unknown'
ğŸ”® DEBUG: frame_data = True
ğŸ”® IjepaPredictor: Got frame 0
ğŸ”® DEBUG: metadata keys = dict_keys(['frame_id', 'timestamp', 'slot', 'buffer_size', 'rgb_shape', 'depth_shape', 'is_valid', 'is_copy', 'processed_by'])
ğŸ”® DEBUG: last_processed_frame_id = -1, frame_skip = 8
ğŸ”® DEBUG: Processing frame 0
ğŸ”® IjepaPredictor: Frame is dict, extracting numpy array
ğŸ”® DEBUG: dict keys = dict_keys(['rgb', 'depth'])
ğŸ”® DEBUG: Using 'rgb' key, shape = (480, 640, 3)
ğŸ”® IjepaPredictor: Frame shape: (480, 640, 3)
ğŸ”® DEBUG: Frame dtype = uint8, min = 0, max = 243
ğŸ”® DEBUG: Calling extract_structural_embedding()
ğŸ”® I-JEPA: Processing (480, 640, 3) â†’ PIL (640, 480)
ğŸ”® I-JEPA: Input tensor torch.Size([1, 3, 224, 224])
   - pixel_values min/max: -1.792/1.989
ğŸ” OWL DEBUG: Inputs keys: ['input_ids', 'attention_mask', 'pixel_values']
ğŸ” OWL DEBUG: Text queries: ['tv']
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 0.89s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â­ï¸ Skipping - trans=0.000m, rot=0.000rad, time=0.9s
ğŸ”   All below thresholds: trans<0.240, rot<0.100, time<1.0
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 1.39s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 1.4s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 1.91s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 1.9s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ”® I-JEPA: Hidden state torch.Size([1, 256, 1280])
ğŸ”® I-JEPA: âœ… Embedding torch.Size([1, 1280])
ğŸ”® DEBUG: Embedding returned = True
ğŸ”® IjepaPredictor: Embedding shape: torch.Size([1, 1280])
ğŸ”® DEBUG: Embedding device = cuda:0
ğŸ”® DEBUG: Embedding dtype = torch.float32
ğŸ”® DEBUG: Raw embedding numpy shape = (1280,)
ğŸ”® DEBUG: Stored embedding for frame 0
ğŸ”® IjepaPredictor: Analyzing current structure with prototypes
============================================================
ğŸ”® _analyze_current_structure CALLED
ğŸ”® embedding_tensor shape = torch.Size([1, 1280])
ğŸ”® embedding_tensor device = cuda:0
ğŸ”® embedding_tensor dtype = torch.float32
============================================================
ğŸ”® _compute_similarities CALLED
ğŸ”® embedding_tensor initial shape = torch.Size([1, 1280])
ğŸ”® embedding_tensor device = cuda:0
----------------------------------------
ğŸ”® Prototype name = free_space
ğŸ”® Prototype original type = <class 'torch.Tensor'>
ğŸ”® Prototype shape = torch.Size([1, 1280])
ğŸ”® Embedding shape = torch.Size([1, 1280])
ğŸ”® similarity = 0.5806
ğŸ”® distance = 0.4194
ğŸ”® best_match = False
ğŸ”® FINAL similarities dict:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Raw similarities:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Extracted similarity_scores:
{'free_space': 0.5806429386138916}
ğŸ”® _analyze_current_structure RESULT â†“â†“â†“
{'type': 'free_space', 'confidence': 0.5806429386138916, 'properties': {'free_space': 0.5806429386138916}}
ğŸ”® _analyze_current_structure RESULT â†‘â†‘â†‘
ğŸ”® IjepaPredictor: Structure type = free_space
ğŸ”® IjepaPredictor: Confidence = 0.581
ğŸ”® DEBUG: Structure properties = ['free_space']
ğŸ”® DEBUG: free_space: 0.581
ğŸ”® DEBUG: Task store available, getting planned actions
ğŸ”® DEBUG: Could not get planned actions: 'TaskStore' object has no attribute 'get_current_task'
ğŸ”® DEBUG: Using actions = ['move_forward', 'turn_left', 'turn_right']
ğŸ”® IjepaPredictor: Analyzing 3 actions
ğŸ”® IjepaPredictor: Analyzing action: move_forward
============================================================
ğŸ”® _analyze_action_continuity CALLED
ğŸ”® action = move_forward
ğŸ”® current_structure = {'type': 'free_space', 'confidence': 0.5806429386138916, 'properties': {'free_space': 0.5806429386138916}}
ğŸ”® map_context = None
ğŸ”® current_embedding shape = torch.Size([1, 1280])
ğŸ”® current_embedding device = cuda:0
ğŸ”® current_embedding dtype = torch.float32
============================================================
ğŸ”® _compute_similarities CALLED
ğŸ”® embedding_tensor initial shape = torch.Size([1, 1280])
ğŸ”® embedding_tensor device = cuda:0
----------------------------------------
ğŸ”® Prototype name = free_space
ğŸ”® Prototype original type = <class 'torch.Tensor'>
ğŸ”® Prototype shape = torch.Size([1, 1280])
ğŸ”® Embedding shape = torch.Size([1, 1280])
ğŸ”® similarity = 0.5806
ğŸ”® distance = 0.4194
ğŸ”® best_match = False
ğŸ”® FINAL similarities dict:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Raw similarities returned:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Extracted similarity_scores:
{'free_space': 0.5806429386138916}
ğŸ”® continuity_score (from similarities) = 0.2903214693069458
ğŸ”® No map_context â†’ default map_confidence = 0.5
ğŸ”® _analyze_action_continuity RESULT â†“â†“â†“
{'action': 'move_forward', 'continuity_score': 0.2903214693069458, 'map_context_confidence': 0.5, 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'continuity_type': 'structural_break', 'similarity_scores': {'free_space': 0.5806429386138916}}
ğŸ”® _analyze_action_continuity RESULT â†‘â†‘â†‘
[DEBUG] Assessing risk: continuity=0.290, stability=0.500
[DEBUG] Prototype stats: avg=0.581, max=0.581
[DEBUG] Risk components: continuity=0.355, prototype=0.126
[DEBUG] Final risk: score=0.481, level=medium
ğŸ”® DEBUG: move_forward continuity = 0.290, risk = medium
ğŸ”® IjepaPredictor: Analyzing action: turn_left
============================================================
ğŸ”® _analyze_action_continuity CALLED
ğŸ”® action = turn_left
ğŸ”® current_structure = {'type': 'free_space', 'confidence': 0.5806429386138916, 'properties': {'free_space': 0.5806429386138916}}
ğŸ”® map_context = None
ğŸ”® current_embedding shape = torch.Size([1, 1280])
ğŸ”® current_embedding device = cuda:0
ğŸ”® current_embedding dtype = torch.float32
============================================================
ğŸ”® _compute_similarities CALLED
ğŸ”® embedding_tensor initial shape = torch.Size([1, 1280])
ğŸ”® embedding_tensor device = cuda:0
----------------------------------------
ğŸ”® Prototype name = free_space
ğŸ”® Prototype original type = <class 'torch.Tensor'>
ğŸ”® Prototype shape = torch.Size([1, 1280])
ğŸ”® Embedding shape = torch.Size([1, 1280])
ğŸ”® similarity = 0.5806
ğŸ”® distance = 0.4194
ğŸ”® best_match = False
ğŸ”® FINAL similarities dict:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Raw similarities returned:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Extracted similarity_scores:
{'free_space': 0.5806429386138916}
ğŸ”® continuity_score (from similarities) = 0.17419288158416749
ğŸ”® No map_context â†’ default map_confidence = 0.5
ğŸ”® _analyze_action_continuity RESULT â†“â†“â†“
{'action': 'turn_left', 'continuity_score': 0.17419288158416749, 'map_context_confidence': 0.5, 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'continuity_type': 'structural_break', 'similarity_scores': {'free_space': 0.5806429386138916}}
ğŸ”® _analyze_action_continuity RESULT â†‘â†‘â†‘
[DEBUG] Assessing risk: continuity=0.174, stability=0.500
[DEBUG] Prototype stats: avg=0.581, max=0.581
[DEBUG] Risk components: continuity=0.413, prototype=0.126
[DEBUG] Final risk: score=0.539, level=medium
ğŸ”® DEBUG: turn_left continuity = 0.174, risk = medium
ğŸ”® IjepaPredictor: Analyzing action: turn_right
============================================================
ğŸ”® _analyze_action_continuity CALLED
ğŸ”® action = turn_right
ğŸ”® current_structure = {'type': 'free_space', 'confidence': 0.5806429386138916, 'properties': {'free_space': 0.5806429386138916}}
ğŸ”® map_context = None
ğŸ”® current_embedding shape = torch.Size([1, 1280])
ğŸ”® current_embedding device = cuda:0
ğŸ”® current_embedding dtype = torch.float32
============================================================
ğŸ”® _compute_similarities CALLED
ğŸ”® embedding_tensor initial shape = torch.Size([1, 1280])
ğŸ”® embedding_tensor device = cuda:0
----------------------------------------
ğŸ”® Prototype name = free_space
ğŸ”® Prototype original type = <class 'torch.Tensor'>
ğŸ”® Prototype shape = torch.Size([1, 1280])
ğŸ”® Embedding shape = torch.Size([1, 1280])
ğŸ”® similarity = 0.5806
ğŸ”® distance = 0.4194
ğŸ”® best_match = False
ğŸ”® FINAL similarities dict:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Raw similarities returned:
{'free_space': {'similarity': 0.5806429386138916, 'distance': 0.4193570613861084, 'best_match': False}}
ğŸ”® Extracted similarity_scores:
{'free_space': 0.5806429386138916}
ğŸ”® continuity_score (from similarities) = 0.17419288158416749
ğŸ”® No map_context â†’ default map_confidence = 0.5
ğŸ”® _analyze_action_continuity RESULT â†“â†“â†“
{'action': 'turn_right', 'continuity_score': 0.17419288158416749, 'map_context_confidence': 0.5, 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'continuity_type': 'structural_break', 'similarity_scores': {'free_space': 0.5806429386138916}}
ğŸ”® _analyze_action_continuity RESULT â†‘â†‘â†‘
[DEBUG] Assessing risk: continuity=0.174, stability=0.500
[DEBUG] Prototype stats: avg=0.581, max=0.581
[DEBUG] Risk components: continuity=0.413, prototype=0.126
[DEBUG] Final risk: score=0.539, level=medium
ğŸ”® DEBUG: turn_right continuity = 0.174, risk = medium
ğŸ”® IjepaPredictor: Building result dictionary
ğŸ”® DEBUG: Updating structural history
ğŸ”® IjepaPredictor: Attempting to save results to store...
ğŸ“Š PredictionStore: Updated pred_reason_1767143847273_1767143852369 with structural_continuity results
ğŸ’¾ 1 predictions saved to predictions.json
ğŸ”® IjepaPredictor: âœ… Successfully saved to prediction store
ğŸ”® DEBUG: Attempting save_to_disk()
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 2.44s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 2.4s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ’¾ 1 predictions saved to predictions.json
ğŸ”® DEBUG: save_to_disk() completed
ğŸ”® DEBUG: Cached analysis for frame skipping
ğŸ”® IjepaPredictor: _execute_prediction_logic completed successfully in 2092.0ms
ğŸ”® DEBUG: Final result keys = ['prediction_id', 'predictor_type', 'timestamp', 'status', 'structural_analysis', 'continuity_predictions', 'structural_risks', 'processing_metrics', 'data_sources_used']
ğŸ”® IjepaPredictor: Result type = <class 'dict'>
Result dict : {'prediction_id': 'pred_reason_1767143847273_1767143852369', 'predictor_type': 'structural_continuity', 'timestamp': 1767143854.3813615, 'status': 'completed', 'structural_analysis': {'current_structure_type': 'free_space', 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'frame_id': 0, 'similarity_scores': {'free_space': 0.5806429386138916}}, 'continuity_predictions': {'move_forward': {'action': 'move_forward', 'continuity_score': 0.2903214693069458, 'map_context_confidence': 0.5, 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'continuity_type': 'structural_break', 'similarity_scores': {'free_space': 0.5806429386138916}}, 'turn_left': {'action': 'turn_left', 'continuity_score': 0.17419288158416749, 'map_context_confidence': 0.5, 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'continuity_type': 'structural_break', 'similarity_scores': {'free_space': 0.5806429386138916}}, 'turn_right': {'action': 'turn_right', 'continuity_score': 0.17419288158416749, 'map_context_confidence': 0.5, 'structural_confidence': 0.5806429386138916, 'embedding_stability': 0.5, 'continuity_type': 'structural_break', 'similarity_scores': {'free_space': 0.5806429386138916}}}, 'structural_risks': {'move_forward': {'risk_level': 'medium', 'risk_score': 0.4806463837623596, 'continuity_score': 0.2903214693069458, 'prototype_similarity': 0.5806429386138916, 'stability': 0.5, 'factors': {'low_continuity': True, 'low_prototype_similarity': False, 'low_stability': True, 'structural_break': True, 'no_prototype_match': False}, 'similarity_contributions': {'free_space': 0.5806429386138916}, 'risk_components': {'continuity_risk': 0.3548392653465271, 'prototype_risk': 0.1258071184158325, 'stability_penalty': 0.0}}, 'turn_left': {'risk_level': 'medium', 'risk_score': 0.5387106776237488, 'continuity_score': 0.17419288158416749, 'prototype_similarity': 0.5806429386138916, 'stability': 0.5, 'factors': {'low_continuity': True, 'low_prototype_similarity': False, 'low_stability': True, 'structural_break': True, 'no_prototype_match': False}, 'similarity_contributions': {'free_space': 0.5806429386138916}, 'risk_components': {'continuity_risk': 0.41290355920791627, 'prototype_risk': 0.1258071184158325, 'stability_penalty': 0.0}}, 'turn_right': {'risk_level': 'medium', 'risk_score': 0.5387106776237488, 'continuity_score': 0.17419288158416749, 'prototype_similarity': 0.5806429386138916, 'stability': 0.5, 'factors': {'low_continuity': True, 'low_prototype_similarity': False, 'low_stability': True, 'structural_break': True, 'no_prototype_match': False}, 'similarity_contributions': {'free_space': 0.5806429386138916}, 'risk_components': {'continuity_risk': 0.41290355920791627, 'prototype_risk': 0.1258071184158325, 'stability_penalty': 0.0}}}, 'processing_metrics': {'processing_time_ms': 2011.0280513763428, 'frame_id': 0, 'model_used': 'ijepa', 'prototypes_loaded': 1}, 'data_sources_used': {'frame_buffer': True, 'prediction_store': True, 'task_store': True, 'prototypes_available': True}}
ğŸ”® DEBUG: I-JEPA result type = <class 'dict'>
ğŸ”® DEBUG: I-JEPA result is dict with keys: dict_keys(['prediction_id', 'predictor_type', 'timestamp', 'status', 'structural_analysis', 'continuity_predictions', 'structural_risks', 'processing_metrics', 'data_sources_used'])
ğŸ”® DEBUG: Waiting for fused results...

ğŸ§  FUSION START | prediction_id = pred_reason_1767143847273_1767143852369
âœ… Data extracted: collision_actions=3, structural_risks=3
ğŸ“Š Data Quality | collision=0.90 structural=0.60
â¡ï¸ move_forward: combined_risk=0.204 decision=proceed
â¡ï¸ turn_left: combined_risk=0.204 decision=proceed
â¡ï¸ turn_right: combined_risk=0.204 decision=proceed
ğŸ›¡ï¸ Overall Safety=safe | Recommended=move_forward | MaxRisk=0.204
ğŸ“Š ReasoningPipeline: Trigger count: 1 - running reasoning cycle
Storing metadata/init for cycle: reason_1767143854462
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ’¾ TASKSTORE: Saved current state to experiments/results/task_store_current.json
ğŸ§  Starting reasoning cycle: reason_1767143854462
  ğŸ§  Running Tree of Thoughts sequentially...
ğŸ¯ TOT DEBUG: LLM available: True
ğŸ” DEBUG generate_comprehensive_plan: Starting with cycle_id=reason_1767143854462
ğŸ” DEBUG generate_comprehensive_plan: LLM available=True
ğŸ” DEBUG generate_comprehensive_plan: Stage 1 completed
ğŸ” DEBUG generate_comprehensive_plan: Stage 2 completed
ğŸ” DEBUG _stage1_strategy_selection: Starting stage 1
ğŸ” DEBUG _extract_minimal_context: Extracting from stores
ğŸ” DEBUG _extract_minimal_context: self.map_store=True, self.user_command_store=True
ğŸ” DEBUG _get_mission_from_command_store: active_command=False
ğŸ” DEBUG _get_world_from_map_store: Entering
ğŸ” CENTRAL MAP STORE DEBUG:
   self.current_pose type: <class 'src.stores.central_map_store.CameraPose'>
   self.current_pose value: CameraPose(position=[0.0, 0.0, 0.0], rotation_quat=[0.0, 0.0, 0.0, 1.0], transform_matrix=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]], timestamp=0.0, frame_id=0, tracking_quality=1.0)
âœ… Retrieved map_summary successfully
ğŸ” map_summary keys: ['geometric_points_count', 'trajectory_length', 'explored_positions_count', 'stored_poses_count', 'objects_count', 'found_targets', 'remaining_targets', 'current_room', 'rooms_visited_count', 'room_history', 'current_pose', 'has_transform_matrix', 'last_update_time', 'uptime_seconds', 'update_counts', 'exploration_progress']
ğŸ” room_type: unknown
âœ… Got 0 objects from semantic_objects
âœ… _get_world_from_map_store SUCCESS (no CameraPose): {'room_type': 'unknown', 'key_objects': [], 'objects_count': 0, 'current_position': [0, 0]}
ğŸ” DEBUG _get_risk_from_prediction_store: Entering
ğŸ” DEBUG _get_risk_from_prediction_store: self.prediction_store type=<class 'src.stores.prediction_store.PredictionStore'>
ğŸ” DEBUG _stage1_strategy_selection: Context extracted: mission=unknown
ğŸ” DEBUG Prompt length: 375 chars
ğŸ” MODEL OUTPUT DEBUG:
   - Output type: <class 'transformers.models.owlvit.modeling_owlvit.OwlViTObjectDetectionOutput'>
   - logits shape: torch.Size([1, 576, 1])
   - logits min/max: -20.258/-6.966
   - pred_boxes shape: torch.Size([1, 576, 4])
ğŸ” POST-PROCESSING DEBUG:
   - target_sizes: tensor([[480, 640]], device='cuda:0')
   - confidence_threshold: 0.05
ğŸ” POST-PROCESS RESULTS DEBUG:
   - Results type: <class 'list'>
   - Results length: 1
ğŸ” RAW RESULT DEBUG:
   - Scores shape: torch.Size([0])
   - Labels shape: torch.Size([0])
   - Boxes shape: torch.Size([0, 4])
ğŸ¯ ALL SCORES:
ğŸ” CONFIDENCE STATS in:
   - Total predictions: 0
   - Passing threshold: 0
ğŸ¯ DEBUG: Raw results - scores: 0, labels: 0
âœ… OWL-ViT found 0 objects
ğŸ¯ 2D detections: 0
âœ… OWL: Got ALREADY-TRANSFORMED pose for frame 0
ğŸ“ Camera pose available
ğŸ”„ Projecting detections to 3D
ğŸ¯ PROJECTION: Starting 3D projection for 0 detections
ğŸ¯ PROJECTION: Camera pose available: True
ğŸ¯ PROJ DEBUG 1: Starting projection for frame 0
ğŸ¯ PROJ DEBUG 1.5: Detections count: 0
ğŸ¯ ORB-SLAM VERIFY: Camera pose OK for frame 0
   Position: [[1. 0. 0. 0.]
 [0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [0. 0. 0. 1.]]
ğŸ¯ PROJ DEBUG 9: Using passed frame_dict, keys: dict_keys(['rgb', 'depth'])
ğŸ¯ PROJ DEBUG 10: depth_frame type: <class 'numpy.ndarray'>
ğŸ¯ PROJ DEBUG 13: Height: 480, Width: 640
ğŸ¯ PROJ DEBUG 14: Intrinsics: fx=320.00000000000006, fy=320.00000000000006
âœ… Projected 0 objects using pixel+depth+pose
ğŸ¯ PROJECTION: ORB-SLAM returned 0 objects
ğŸŒ 3D objects projected: 0
Tracking 0 objects after update
ğŸ§­ Objects after tracking: 0
Updated semantic store for frame 0 with 0 objects
ğŸ—ºï¸  Shared map store updated
â±ï¸  Processing time: 2.290s
ğŸ“Š Counters â†’ processed=1, avg_time=2.290s
âœ… OWL DEBUG â”€â”€â”€ END FRAME 0 â”€â”€â”€

ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 2.94s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 2.9s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 3.47s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 3.5s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 3.99s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 4.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 4.51s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 4.5s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 5.04s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 5.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 5.56s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 5.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 6.08s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 6.1s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG Raw response: Proximity First
âœ… Extracted strategy: proximity_first
ğŸ” DEBUG _stage1_strategy_selection: Strategy decision: proximity_first
ğŸ” STAGE2 DEBUG: strategy_decision keys = ['strategy_type', 'strategy_reasoning', 'confidence', 'mission_analysis', 'key_considerations', 'raw_prompt', 'raw_response', 'context_objects']
ğŸ” STAGE2 DEBUG: strategy_type = proximity_first
ğŸ” STAGE2 DEBUG: raw_response = Proximity First
ğŸ” DEBUG _get_world_from_map_store: Entering
ğŸ” CENTRAL MAP STORE DEBUG:
   self.current_pose type: <class 'src.stores.central_map_store.CameraPose'>
   self.current_pose value: CameraPose(position=[0.0, 0.0, 0.0], rotation_quat=[0.0, 0.0, 0.0, 1.0], transform_matrix=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]], timestamp=0.0, frame_id=0, tracking_quality=1.0)
âœ… Retrieved map_summary successfully
ğŸ” map_summary keys: ['geometric_points_count', 'trajectory_length', 'explored_positions_count', 'stored_poses_count', 'objects_count', 'found_targets', 'remaining_targets', 'current_room', 'rooms_visited_count', 'room_history', 'current_pose', 'has_transform_matrix', 'last_update_time', 'uptime_seconds', 'update_counts', 'exploration_progress']
ğŸ” room_type: unknown
âœ… Got 0 objects from semantic_objects
âœ… _get_world_from_map_store SUCCESS (no CameraPose): {'room_type': 'unknown', 'key_objects': [], 'objects_count': 0, 'current_position': [0, 0]}
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 6.61s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 6.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 7.14s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 7.1s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 7.66s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 7.7s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 8.19s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 8.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 8.71s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 8.7s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 9.23s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 9.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 9.75s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 9.7s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 10.27s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 10.3s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 10.79s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 10.8s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 11.32s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 11.3s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 11.84s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 11.8s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 12.37s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 12.4s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 12.90s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 12.9s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 13.42s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 13.4s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 13.95s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 13.9s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 14.47s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 14.5s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 15.00s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 15.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 15.52s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 15.5s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 16.05s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 16.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 16.57s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 16.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 17.10s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 17.1s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14        0.98967767 -2.52      ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 17.62s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 17.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ” DEBUG Stage 2 Raw response: {"target_objects":["object1","object2","object3"],"search_pattern":"pattern description","reasoning":"why this order","expected_success":0.7,"fallback_objects":["object4","object5"]}...
ğŸ” TEXT PARSER: Parsing 182 chars
ğŸ” TEXT PARSER INPUT: '{"target_objects":["object1","object2","object3"],"search_pattern":"pattern description","reasoning":"why this order","expected_success":0.7,"fallback_objects":["object4","object5"]}...'
ğŸ” TEXT PARSER: Cleaned from 182 to 182 chars
ğŸ” TEXT PARSER CLEANED: '{"target_objects":["object1","object2","object3"],"search_pattern":"pattern description","reasoning":"why this order","expected_success":0.7,"fallback...'
ğŸ” TEXT PARSER PHASE 1: Looking for JSON pattern...
âœ… TEXT PARSER: Found JSON pattern, 182 chars
ğŸ” TEXT PARSER JSON EXTRACT: '{"target_objects":["object1","object2","object3"],"search_pattern":"pattern description","reasoning":"why this order","expected_success":0.7,"fallback...'
âœ… TEXT PARSER: JSON parsed successfully
ğŸ” TEXT PARSER JSON TYPE: <class 'dict'>
âœ… TEXT PARSER SUCCESS: Extracted 3 targets from JSON
ğŸ” TEXT PARSER JSON RESULT: targets=['object1', 'object2', 'object3'], pattern=pattern description
ğŸ” TEXT PARSER JSON FULL: {'target_objects': ['object1', 'object2', 'object3'], 'search_pattern': 'pattern description', 'reasoning': 'why this order', 'expected_success': 0.7, 'fallback_objects': ['object4', 'object5'], 'parsed_from_text': True, 'parser_debug': {}, 'parsed_from_json': True}
ğŸ” STAGE2 PARSED plan_data type: <class 'dict'>
ğŸ” STAGE2 PARSED plan_data keys: ['target_objects', 'search_pattern', 'reasoning', 'expected_success', 'fallback_objects', 'parsed_from_text', 'parser_debug', 'parsed_from_json']
âš ï¸ No Umeyama goal found for 'object1', returning empty list
âš ï¸ No Umeyama goal found for 'object2', returning empty list
âš ï¸ No Umeyama goal found for 'object3', returning empty list
ğŸ” DEBUG _build_complete_plan: Building complete plan for cycle_id=reason_1767143854462
ğŸ” DEBUG _build_complete_plan: strategy_type=proximity_first
ğŸ” DEBUG _extract_minimal_context: Extracting from stores
ğŸ” DEBUG _extract_minimal_context: self.map_store=True, self.user_command_store=True
ğŸ” DEBUG _get_mission_from_command_store: active_command=False
ğŸ” DEBUG _get_world_from_map_store: Entering
ğŸ” CENTRAL MAP STORE DEBUG:
   self.current_pose type: <class 'src.stores.central_map_store.CameraPose'>
   self.current_pose value: CameraPose(position=[0.0, 0.0, 0.0], rotation_quat=[0.0, 0.0, 0.0, 1.0], transform_matrix=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]], timestamp=0.0, frame_id=0, tracking_quality=1.0)
âœ… Retrieved map_summary successfully
ğŸ” map_summary keys: ['geometric_points_count', 'trajectory_length', 'explored_positions_count', 'stored_poses_count', 'objects_count', 'found_targets', 'remaining_targets', 'current_room', 'rooms_visited_count', 'room_history', 'current_pose', 'has_transform_matrix', 'last_update_time', 'uptime_seconds', 'update_counts', 'exploration_progress']
ğŸ” room_type: unknown
âœ… Got 0 objects from semantic_objects
âœ… _get_world_from_map_store SUCCESS (no CameraPose): {'room_type': 'unknown', 'key_objects': [], 'objects_count': 0, 'current_position': [0, 0]}
ğŸ” DEBUG _get_risk_from_prediction_store: Entering
ğŸ” DEBUG _get_risk_from_prediction_store: self.prediction_store type=<class 'src.stores.prediction_store.PredictionStore'>
ğŸ” DEBUG _get_world_from_map_store: Entering
ğŸ” CENTRAL MAP STORE DEBUG:
   self.current_pose type: <class 'src.stores.central_map_store.CameraPose'>
   self.current_pose value: CameraPose(position=[0.0, 0.0, 0.0], rotation_quat=[0.0, 0.0, 0.0, 1.0], transform_matrix=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]], timestamp=0.0, frame_id=0, tracking_quality=1.0)
âœ… Retrieved map_summary successfully
ğŸ” map_summary keys: ['geometric_points_count', 'trajectory_length', 'explored_positions_count', 'stored_poses_count', 'objects_count', 'found_targets', 'remaining_targets', 'current_room', 'rooms_visited_count', 'room_history', 'current_pose', 'has_transform_matrix', 'last_update_time', 'uptime_seconds', 'update_counts', 'exploration_progress']
ğŸ” room_type: unknown
âœ… Got 0 objects from semantic_objects
âœ… _get_world_from_map_store SUCCESS (no CameraPose): {'room_type': 'unknown', 'key_objects': [], 'objects_count': 0, 'current_position': [0, 0]}
ğŸ” TOT FULL PLAN (reason_1767143854462): {'reasoning_cycle_id': 'reason_1767143854462', 'timestamp': 1767143870.1290736, 'planning_stages': ['strategy_selection', 'detailed_planning'], 'llm_used': True, 'strategy_decision': {'strategy_type': 'proximity_first', 'strategy_reasoning': 'Proximity First', 'confidence': 0.7, 'mission_analysis': 'Finding keys in unknown', 'key_considerations': ['speed', 'accuracy', 'object locations'], 'raw_prompt': 'Choose best search strategy for finding keys:\n\n        Options: proximity_first, priority_first, systematic_search, room_exploration\n\n        Mission: unknown\n        Location: unknown\n        Objects available: \n\n        Answer with ONE word from the options above, then a brief reason.\n\n        Example: "proximity_first - check closest objects first"\n\n        Your answer:', 'raw_response': 'Proximity First', 'context_objects': []}, 'detailed_plan': {'target_objects': ['object1', 'object2', 'object3'], 'search_pattern': 'pattern description', 'object_priority': ['object1', 'object2', 'object3'], 'reasoning': 'why this order', 'expected_success': 0.7, 'fallback_objects': ['object4', 'object5']}, 'reasoning_chain': [{'stage': 'strategy_selection', 'timestamp': 1767143858.3587933, 'input_context': {'mission': 'unknown', 'room_type': 'unknown', 'key_objects': [], 'objects_count': 0, 'risk_level': 'medium'}, 'llm_prompt': 'Choose best search strategy for finding keys:\n\n        Options: proximity_first, priority_first, systematic_search, room_exploration\n\n        Mission: unknown\n        Location: unknown\n        Objects available: \n\n        Answer with ONE word from the options above, then a brief reason.\n\n        Exa', 'llm_response': 'Proximity First', 'output_reasoning': {'strategy_type': 'proximity_first', 'strategy_reasoning': 'Proximity First', 'confidence': 0.7}}, {'stage': 'detailed_planning', 'timestamp': 1767143870.1290352, 'input_context': {'mission': 'Finding keys in unknown', 'strategy': 'proximity_first', 'stage1_reasoning': 'Proximity First', 'available_objects': []}, 'llm_prompt': 'Based on this strategy reasoning, create a search plan:\n\n        STRATEGY CHOSEN: proximity_first\n        REASONING: Proximity First\n\n        CREATE SEARCH PLAN FOR: Finding keys in unknown\n        AVAILABLE OBJECTS: \n\n        Return ONLY this JSON:\n        {\n            "target_objects": ["object1"', 'llm_response': '{"target_objects":["object1","object2","object3"],"search_pattern":"pattern description","reasoning":"why this order","expected_success":0.7,"fallback_objects":["object4","object5"]}', 'output_reasoning': {'target_objects': ['object1', 'object2', 'object3'], 'search_pattern': 'pattern description', 'object_priority': ['object1', 'object2', 'object3'], 'reasoning': 'why this order', 'expected_success': 0.7, 'parsed_from_json': True}}], 'input_context': {'minimal_context': {'mission': 'unknown', 'room_type': 'unknown', 'key_objects': [], 'objects_count': 0, 'risk_level': 'medium'}, 'focused_context': {'mission': 'Finding keys in unknown', 'room_type': 'unknown', 'relevant_objects': [], 'current_position': [0, 0]}}, 'execution_ready_plan': {'strategy_type': 'proximity_first', 'search_pattern': 'pattern description', 'expected_duration': 'medium'}}
Storing INTERMEDIATE reasoning for cycle: reason_1767143854462
ğŸ’¾ TASKSTORE: Saved current state to experiments/results/task_store_current.json
âœ… Generated comprehensive plan from Tree Of Thoughts reasoning reason_1767143854462
ğŸ” TOT DEBUG: Time after completion: 1767143870.1385987
  âœ… Tree of Thoughts completed
  ğŸ” DEBUG: Tree of Thoughts output: {'reasoning_cycle_id': 'reason_1767143854462'}
  ğŸ—ºï¸ Running Spatial Reasoning sequentially...
ğŸ¯ Spatial Reasoning: Starting analysis for cycle reason_1767143854462
ğŸ” DEBUG: Found 0 semantic objects in MapStore
================================================================================
ğŸ” _fetch_all_spatial_data() - DEBUG START
================================================================================
ğŸ“Š STORE CHECK:
  â€¢ map_store exists: True
  â€¢ map_store type: <class 'src.stores.central_map_store.CentralMapStore'>
  â€¢ map_store dir: ['add_collision', 'add_geometric_points_rich', 'clear_collisions', 'clear_map', 'collision_points', 'config', 'creation_time', 'current_pose', 'current_room', 'explored_positions']...

ğŸ¯ STEP 1: Fetching semantic objects
  âœ… Found semantic_objects attribute
  â€¢ Total semantic objects: 0

ğŸ“ STEP 2: Fetching robot position
  âœ… Found current_pose attribute
  â€¢ Robot position: [0.0, 0.0, 0.0]
  â€¢ Position type: <class 'list'>

ğŸšª STEP 3: Fetching current room
  âœ… Found current_room attribute
  â€¢ Current room: unknown

ğŸ“¦ MAP_DATA SUMMARY:
  â€¢ Objects: 0 items
  â€¢ Robot position: [0.0, 0.0, 0.0]
  â€¢ Current room: unknown

ğŸ¯ STEP 4: Fetching task goal
  âœ… task_store exists
  â€¢ Calling get_task_summary()
  âŒ Failed to get task goal: 'dict' object has no attribute 'id'
  â€¢ Final task_goal keys: ['current_mission', 'search_progress', 'explored_rooms', 'current_task', 'umeyama_aligned_goals', 'mission_goals_list']

ğŸ”® STEP 5: Fetching predictions
  âœ… prediction_store exists
  âŒ prediction_store has no get_predictions method

âœ… FINAL DATA STRUCTURE:
  â€¢ map_data objects: 0
  â€¢ task_goal keys: 6
  â€¢ predictions type: <class 'dict'>
================================================================================
âœ… _fetch_all_spatial_data() - DEBUG COMPLETE
================================================================================
================================================================================
ğŸ” _fetch_all_spatial_data() - DEBUG START
================================================================================
ğŸ“Š STORE CHECK:
  â€¢ map_store exists: True
  â€¢ map_store type: <class 'src.stores.central_map_store.CentralMapStore'>
  â€¢ map_store dir: ['add_collision', 'add_geometric_points_rich', 'clear_collisions', 'clear_map', 'collision_points', 'config', 'creation_time', 'current_pose', 'current_room', 'explored_positions']...

ğŸ¯ STEP 1: Fetching semantic objects
  âœ… Found semantic_objects attribute
  â€¢ Total semantic objects: 0

ğŸ“ STEP 2: Fetching robot position
  âœ… Found current_pose attribute
  â€¢ Robot position: [0.0, 0.0, 0.0]
  â€¢ Position type: <class 'list'>

ğŸšª STEP 3: Fetching current room
  âœ… Found current_room attribute
  â€¢ Current room: unknown

ğŸ“¦ MAP_DATA SUMMARY:
  â€¢ Objects: 0 items
  â€¢ Robot position: [0.0, 0.0, 0.0]
  â€¢ Current room: unknown

ğŸ¯ STEP 4: Fetching task goal
  âœ… task_store exists
  â€¢ Calling get_task_summary()
  âŒ Failed to get task goal: 'dict' object has no attribute 'id'
  â€¢ Final task_goal keys: ['current_mission', 'search_progress', 'explored_rooms', 'current_task', 'umeyama_aligned_goals', 'mission_goals_list']

ğŸ”® STEP 5: Fetching predictions
  âœ… prediction_store exists
  âŒ prediction_store has no get_predictions method

âœ… FINAL DATA STRUCTURE:
  â€¢ map_data objects: 0
  â€¢ task_goal keys: 6
  â€¢ predictions type: <class 'dict'>
================================================================================
âœ… _fetch_all_spatial_data() - DEBUG COMPLETE
================================================================================
ğŸ” get_all_map_points: Found 843 points
ğŸ” CENTRAL MAP STORE DEBUG:
   self.current_pose type: <class 'src.stores.central_map_store.CameraPose'>   "strategy_type": "priority_first",
      "target_objects": [
        "table",
        "cabinet",
        "nightstand"
      ],
      "expected_duration": "medium",
      "navigation_constraints": {
        "max_speed": 0.3,
        "avoid_areas": []
      }
    },
    "task_status": {
      "status": "pending_execution",
      "execution_attempts": 0,
      "completion_status": "not_started"
    }
  },
  "current_task": {
    "task_id": "perception_pipeline",
    "created_at": 1767143850.1624207,
    "perception_status": "initialized",
    "last_update": 1767143850.1624236
  }
} ‹           á       ; Ár  “‹                                   ¬ÿŠ           
   self.current_pose value: CameraPose(position=[0.0, 0.0, 0.0], rotation_quat=[0.0, 0.0, 0.0, 1.0], transform_matrix=[[1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 1.0]], timestamp=0.0, frame_id=0, tracking_quality=1.0)
ğŸ” get_all_map_points: Found 843 points
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 0 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 0
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ“ Found ORB-SLAM map: projects/hybrid_zero_shot_slam_nav/main/experiments/results/logs/orbslam_map.json
âœ… Robot parameters calculated from real data:
   Radius: 0.50m, Clearance: 0.35m, Reach: 0.06m
âœ… Spatial reasoning stored in intermediate_reasoning for reason_1767143854462
âœ… Spatial reasoning completed for cycle: reason_1767143854462
   ğŸ“Š Results: 0 reachable objects, 0 risk zones, 0 prioritized objects
ğŸ” SPATIAL REASONING FULL OUTPUT (reason_1767143854462):
{
  "reachability_analysis": {
    "reachable_objects": [],
    "total_reachable": 0,
    "unreachable_reason": "distance_or_risk"
  },
  "search_strategy": {
    "priority_list": [],
    "top_priority": null,
    "total_objects_prioritized": 0
  },
  "safety_analysis": {
    "risk_zones": [],
    "high_risk_count": 0,
    "medium_risk_count": 0
  },
  "perception_analysis": {
    "visibility_scores": {},
    "best_visible": null,
    "worst_visible": null
  },
  "navigation_analysis": {
    "path_feasibility": {},
    "most_feasible_room": null,
    "least_feasible_room": null
  },
  "exploration_analysis": {
    "room_connectivity": [],
    "unexplored_rooms": [],
    "next_exploration_target": null
  },
  "recommendations": [
    "Continue current exploration pattern"
  ],
  "summary_metrics": {
    "total_objects_analyzed": 0,
    "safe_navigation_paths": 0,
    "exploration_progress": 0.0
  },
  "reasoning_cycle_id": "reason_1767143854462",
  "component_name": "spatial_reasoning",
  "pipeline_timestamp": 1767143870.173725,
  "processing_stages": [
    "reachability",
    "priority",
    "risk",
    "visibility",
    "navigation",
    "exploration"
  ]
}
  âœ… Spatial Reasoning completed
  ğŸ” DEBUG: Spatial Reasoning output: {'reasoning_cycle_id': 'reason_1767143854462'}
ğŸ“Š ReasoningPipeline: Components completed - ['tree_of_thoughts', 'spatial_reasoning']
âœ… Retrieved Tree of Thoughts from intermediate_reasoning
âœ… Retrieved Spatial Reasoning from intermediate_reasoning
ğŸ“Š ReasoningPipeline: Retrieved data from 2 components: ['tree_of_thoughts', 'spatial_reasoning']
================================================================================
ğŸ” FUSION DEBUG: INPUT COMPONENT DATA
All component keys: ['tree_of_thoughts', 'spatial_reasoning']
================================================================================
âœ… FUSING BOTH: tree_of_thoughts + spatial_reasoning
Spatial Object Map: {}
ğŸ” SPATIAL DATA CHECK:
  â€¢ No spatial priority list
âœ… FUSED BOTH: Created 3 rich actions
================================================================================
ğŸ” FUSION DEBUG: FINAL FUSED RESULT {'selected_action': {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, 'planned_actions': [{'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object2', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object3', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}], 'final_confidence': 0.48999999999999994, 'components_contributing': ['tree_of_thoughts', 'spatial_reasoning'], 'execution_readiness': 'needs_confirmation', 'plan_metadata': {'target_objects': ['object1', 'object2', 'object3'], 'search_pattern': 'pattern description', 'spatial_priorities': [], 'top_priority': None}, 'has_coordinates': False, 'target_objects': ['object1', 'object2', 'object3']}
  Selected action: {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}
  Planned actions: 3
================================================================================
ğŸ¯ ReasoningPipeline: Fusion logic = None, Action = {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, Confidence = 0.49
ğŸ’¾ Saving action plan via write_reasoning_plan...
FINAL ACTION PLAN DETECTED â†’ {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}} (cycle reason_1767143854462)
Triggering action_plan_ready for {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}
TaskStore[125360300869040] notifying 1 subscribers about action_plan_ready
ğŸ§µ Active threads Before on_actionplan_ready: 3
Thread names: ['MainThread', 'Thread-1', 'Thread-2']
ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””
ACTION PLAN RECEIVED â†’ STARTING EXECUTION THREAD
ğŸ”” TASKSTORE TRIGGER RECEIVED!
   ğŸ“¡ Event type: action_plan_ready
   ğŸ“¦ Data keys: ['action_plan', 'timestamp', 'reasoning_cycle_id']
ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””ğŸ””
ğŸ“Š Trigger count: 1
ğŸ“‹ Action plan queue created
ğŸ“¥ ACTION PLAN QUEUED:
   ğŸ¯ Action: {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}
   ğŸ“Š Confidence: 0.49
   ğŸ“ Queue position: 1
   ğŸ†” Plan ID: reason_1767143854462
ğŸ“ˆ Action plan counter initialized
ğŸ“¥ ACTION PLAN started: using _event_driven_started trigger and run_event_driven finction call 
ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯
ğŸ¦¾ ACTION PIPELINE: STARTING EVENT-DRIVEN EXECUTION
ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯
   ğŸ“¡ Mode: Event-driven (no loops)
   â³ Waiting for action plans from ReasoningPipeline...
   ğŸ”” Listening for TaskStore triggers...
Action execution started, start_execution called
âœ… Action executor started
ğŸ”„ Entering event-driven wait loop...
ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯
ğŸš€ EXECUTING ACTION PLAN: '{'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}'
   ğŸ“Š Confidence: 0.49
   ğŸ“‹ Plan ID: reason_1767143854462
   ğŸ“ Source: unknown
ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯ğŸ¯
ğŸ¦¾ Initiating run_execution_cycle method from action executor...
Run Execution cycle from action executor reached
Current Planned actions : [{'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object2', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object3', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}]
Current Planned reference : {'reasoning_cycle_id': 'reason_1767143854462', 'timestamp': 1767143870.1745799, 'selected_action': {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, 'planned_actions': [{'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object2', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}, {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object3', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}], 'confidence': 0.48999999999999994, 'reasoning_source': 'unknown', 'components_used': ['tree_of_thoughts', 'spatial_reasoning'], 'component': 'final_action', 'task_status': 'pending_execution', 'execution_attempts': 0, 'last_execution_attempt': None, 'completion_status': 'not_started', 'execution_metadata': {'requires_confirmation': True, 'estimated_duration': 'pending', 'prerequisites_met': True, 'safety_clearance': 'pending'}}
DEBUG: _execute_actions_in_habitat called with 3 actions
ğŸ¯ ACTION EXECUTOR: Starting execution of execute_single_action: action type : 'move_forward'
ğŸ“ Valid initial pose: [-0.14000000059604645, 1.0, -2.5199999809265137], quat:quaternion(0.315322362395269, 0, 0.948984619355586, 0)
Target coordinates inside action executor: None
âš ï¸ WARNING: target_coordinates is None! Checking HabitatStore...
ğŸ¯ HABITATSTORE: Using stored goal 'tv' at [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
ğŸ¯ CONTINUOUS NAVIGATION to [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
Current quat from Habitat: quaternion(0.315322362395269, 0, 0.948984619355586, 0)
ğŸ”„ Starting CONTINUOUS NAVIGATION to [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
ğŸ” DEBUG: START - pos=[-0.14        1.         -2.51999998], raw_quat=quaternion(0.315322362395269, 0, 0.948984619355586, 0)
ğŸ”„ DEBUG: INITIAL QUAT FLATTENED to [0.0, 0.9489846193555862, 0.0, 0.3153223623952687]
ğŸ” DEBUG: AFTER FLATTEN - yaw=2.500 (143.2Â°)
ğŸ¯ SINGLE TURN ALIGNMENT...
ğŸ” DEBUG: target_xyz=[-0.15094197  2.35249805 -2.47645044]
ğŸ” DEBUG: goal_yaw=-2.895 (-165.9Â°)
ğŸ” DEBUG: yaw_err=0.888 (50.9Â°)
ğŸ” DEBUG: ALIGN NEEDED | align_ang=2.663
â±ï¸ ALIGN DURATION computed = 0.333s (yaw_err=50.9Â°, ang=2.66 rad/s)
ğŸ” DEBUG: align_params={'linear_velocity': [0.0, 0.0, 0.0], 'angular_velocity': [0.0, 2.6632517848714174, 0.0], 'duration': 0.3333333333333333, 'is_velocity_command': True}
ğŸ“¥ HABITATSTORE: Pushing action 'velocity_control' to queue
ğŸ†• HABITATSTORE: Creating new action queue
ğŸ’¾ TASKSTORE: Saved current state to experiments/results/task_store_current.json
ğŸ§  Reasoning cycle reason_1767143854462 completed - Action: {'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}} (Status: pending_execution) (Confidence: 0.49)
ğŸ’¾ Fused prediction stored successfully
âœ… Fusion returned: <class 'dict'>
âœ… Fused keys: dict_keys(['timestamp', 'overall_safety_level', 'recommended_action', 'max_combined_risk', 'action_decisions', 'data_quality', 'risk_summary'])
ğŸ” PREDICTIONS DEBUG - Type: <class 'dict'>
ğŸ” PREDICTIONS DEBUG - Keys: ['timestamp', 'overall_safety_level', 'recommended_action', 'max_combined_risk', 'action_decisions', 'data_quality', 'risk_summary']
ğŸ¯ Using direct fused predictions structure
  ğŸ”® ACTION DECISIONS:
  ğŸ“Š move_forward: risk=0.204, decision=proceed
  ğŸ“Š turn_left: risk=0.204, decision=proceed
  ğŸ“Š turn_right: risk=0.204, decision=proceed
  ğŸ¯ Fused prediction suggests: move_forward
DEBUG: about to write rgb frame
ğŸ“¦ HABITATSTORE: Added metadata to action 'velocity_control'
âœ… HABITATSTORE: Action 'velocity_control' queued (ID: action_1767143870210_0)
ğŸ“Š HABITATSTORE: Queue size: 1
ğŸ” DEBUG: align_id=action_1767143870210_0
ğŸ” DEBUG: WAITING for result...
â³ No result yet for action_1767143870210_0
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ” DEBUG: WAITING - No result yet
â³ No result yet for action_1767143870210_0
ğŸ¥ Agent-1 sensors: ['third_rgb']
ğŸ” DEBUG: WAITING - No result yet
â³ No result yet for action_1767143870210_0
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¥ Spectator frame saved: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005/spectator_view_before_0.png
ğŸ’¡ Processing frame 0 brightness: 142.2
âœ… Frame 0 captured - RGB: (480, 640, 3), Depth: (480, 640)
ğŸ“Š Progress: 1/500 frames (0.2%)
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ” DEBUG: WAITING - No result yet
â³ No result yet for action_1767143870210_0
ğŸ” DEBUG: WAITING - No result yet
â³ No result yet for action_1767143870210_0
ğŸ” Mission check: 1 total goals, 1 remaining
   Mission goals: {'tv'}
   Remaining goals: ['tv']

--- FRAME 2/500 ---
DEBUG: about to get sensor observations
ğŸ¦‰ OWL: starting to Process REAL frame 0 
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: WAITING - No result yet
â³ No result yet for action_1767143870210_0
ğŸ¯ CURRENT SENSORS: ['rgba_camera', 'depth_camera']
DEBUG: about to extract rgb and depth
ğŸ¯ DEPTH STATS - Min: 0.5622655153274536, Max: 2.366044521331787, Mean: 1.080
âœ… Depth frame has 307200 valid pixels
DEBUG: RGBA -> RGB conversion for frame 1
DEBUG: Transposing rgb_frame from (640, 480, 3) to (480, 640, 3)
65¿¿f?Dàˆ>        @ÿÿ¤í?D$¿Bz·¿÷é´¿Ü–ÂŒèC,è€?ó5¿÷g?ÜÚŠ>        @ÿÿ\¾ç?&€¿I(¸¿ı—µ¿0„ÂúÙCMç€?`r4¿ê“d?Ìox>        @ÿÿ¶ì?ÏX¿#Š·¿×ù´¿*’ÂòÚCè€?5¿úf?xa{>        @ÿÿDEBUG: Depth frame shape before transpose: (640, 480)
DEBUG: Depth frame shape after transpose: (480, 640)
DEBUG: Converted depth dtype to uint16
DEBUG: about to rotate rgb frame
DEBUG: about to scale depth
ğŸ¯ DEBUG: Frame 1 - RGB shape: (480, 640, 3), Depth shape: (480, 640)
ğŸ¯ DEBUG: RGB dtype: uint8, Depth dtype: uint16
âœ… DEBUG: Frame 1 written to buffer - Slot 1
âœ… DEBUG: Buffer RGB dtype: uint8, Depth dtype: uint16
  Wrote frame 1 to buffer successfully âœ…
  âœ… Frame 2 captured - RGB: (480, 640, 3), Depth: (480, 640)
ğŸŸ¦ DEBUG: Calling ORB-SLAM process_frame() for frame 1
ğŸŸ© DEBUG: Returned from ORB-SLAM process_frame() for frame 1
ğŸ” Checking for queued actions...
ğŸ¯ HABITATSTORE: Pulling next action from queue
ğŸš€ HABITATSTORE: Pulled VELOCITY CONTROL command
   ğŸ“¦ Metadata: ['target_xyz', 'dist_remaining', 'lin_vel', 'ang_vel', 'yaw_error_deg', 'step_id', 'current_pos', 'predicted_pos', 'continuous_nav', 'velocity_data']
ğŸ“Š HABITATSTORE: Remaining in queue: 0
ğŸ¯ MAINORCH: Executing action 'velocity_control'
================================================================================
ğŸ¯ Executing Habitat action: velocity_control
ğŸ“¦ Parameters: {'linear_velocity': [0.0, 0.0, 0.0], 'angular_velocity': [0.0, 2.6632517848714174, 0.0], 'duration': 0.3333333333333333, 'is_velocity_command': True}
ğŸ“¦ Metadata: {'target_xyz': [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223], 'dist_remaining': 0.0, 'lin_vel': 0.0, 'ang_vel': 2.6632517848714174, 'yaw_error_deg': 50.86436235127189, 'step_id': 0, 'current_pos': [-0.14000000059604645, 1.0, -2.5199999809265137], 'predicted_pos': [-0.14000000059604645, 1.0, -2.5199999809265137], 'continuous_nav': True, 'velocity_data': {'lin_vel': 0.0, 'ang_vel': 2.6632517848714174, 'duration': 0.3333333333333333}}
================================================================================
ğŸ§® Linear velocity: [0.0, 0.0, 0.0], angular velocity: [0.0, 2.6632517848714174, 0.0], dt=0.3333333333333333
âœ… VC created: <class 'habitat_sim._ext.habitat_sim_bindings.VelocityControl'>
âœ… VC lin_vel set: Vector(0, 0, 0)
âœ… VC ang_vel set: Vector(0, 2.66325, 0)
âœ… rb_pos: [-0.14000000059604645, 0.9896776676177979, -2.5199999809265137]
âœ… rb_rot: <class '_magnum.Quaternion'>
âœ… quat_list: [0.0, 0.9489846229553223, 0.0, 0.3153223693370819]
âœ… flat_q: [0.0, 0.9489846186939899, 0.0, 0.31532236438638883], type=<class 'list'>, len=4
ğŸ”§ flat_q[0:4]=[0.0, 0.9489846186939899, 0.0, 0.31532236438638883]
âœ… rigid_state created: pos=Vector(-0.14, 0.989678, -2.52)
ğŸ“ RigidState before integrate: pos=Vector(-0.14, 0.989678, -2.52), rot=Quaternion({0, 0.948985, 0}, 0.315322)
ğŸ“ Predicted new_pos from VelocityControl: [-0.14000000059604645, 0.9896776676177979, -2.5199999809265137]
ğŸ¥ [SPECTATOR] synced to robot
ğŸ¥ [SPECTATOR] cam_pos = Vector(0.342884, 0.879287, -4.46072)
ğŸ’¥ PHYSICS: 7 raw â†’ 0 wall | side=NONE depth=NONE
ğŸ’¥ PHYSICS: 7 contacts - [RigidObject, ./datasets/versioned_data/locobot_merged_0.2/locobot_merged.object_config.json, id 1] vs [Stage, subpart 47], 3 points
[RigidObject, ./datasets/versioned_data/locobot_merged_0.2/locobot_merged.object_config.json, id 1] vs [Stage, subpart 47], 2 points
[RigidObject, ./datasets/versioned_data/locobot_merged_0.2/locobot_merged.object_config.json, id 1] vs [Stage, subpart 47], 1 points
[RigidObject, ./datasets/versioned_data/locobot_merged_0.2/locobot_merged.object_config.json, id 1] vs [Stage, subpart 47], 1 points

ğŸ¯ FINAL COLLISION = False , physics=False)
ğŸ“ Obstacle clearance from the robot before collision= 0.000 m
ğŸ¤– ROBOT POST-PHYSICS pos = [-0.14014077186584473, 0.8792873620986938, -2.519925832748413]
ğŸ¤– ROBOT POST-PHYSICS rot = [0.0, 0.9925718307495117, 0.0, 0.12165989726781845]
ğŸ“ METRICS: Trajectory len = 2
âœ… Velocity motion applied (projected)
ğŸ” DEBUG: WAITING - No result yet
â³ No result yet for action_1767143870210_0
ğŸ” DEBUG: stack[1].function = _continuous_processing_loop
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/owl_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='_continuous_processing_loop [owl_integration.py]', Model='owl'
âš ï¸  Skipping frame 0 for owl (already processed)
âŒ OWL processing error: cannot unpack non-iterable NoneType object
ğŸ‘ rgba_camera shape: (640, 480, 4)
ğŸŒŠ depth_camera shape: (640, 480)
ğŸ“¤ Result (velocity_control): status=completed, collided=False, new_position=[-0.14014077186584473, 0.8792873620986938, -2.519925832748413]
================================================================================
Action in habitat simulation result : {'action_id': 'action_1767143870210_0', 'status': 'completed', 'action': 'velocity_control', 'obstacle_direction': {'side': 'NONE', 'depth': 'NONE'}, 'obstacle_distance': 0.0, 'observations': {'rgba_camera': array([[[131, 121, 121, 255],
        [131, 120, 122, 255],
        [129, 119, 120, 255],
        ...,
        [128, 128, 120, 255],
        [128, 128, 120, 255],
        [128, 128, 120, 255]],

       [[131, 121, 120, 255],
        [129, 120, 119, 255],
        [126, 119, 118, 255],
        ...,
        [128, 128, 120, 255],
        [128, 128, 120, 255],
        [128, 128, 120, 255]],

       [[131, 121, 120, 255],
        [131, 121, 120, 255],
        [126, 119, 117, 255],
        ...,
        [128, 128, 120, 255],
        [128, 128, 120, 255],
        [128, 128, 120, 255]],

       ...,

       [[126, 110,  93, 255],
        [126, 110,  93, 255],
        [126, 110,  93, 255],
        ...,
        [167, 168, 167, 255],
        [167, 168, 167, 255],
        [167, 168, 167, 255]],

       [[126, 110,  93, 255],
        [126, 110,  93, 255],
        [124, 108,  91, 255],
        ...,
        [167, 168, 167, 255],
        [167, 168, 167, 255],
        [167, 168, 167, 255]],

       [[124, 108,  91, 255],
        [124, 108,  91, 255],
        [124, 108,  91, 255],
        ...,
        [167, 168, 167, 255],
        [167, 168, 167, 255],
        [167, 168, 167, 255]]], dtype=uint8), 'depth_camera': array([[0.64467156, 0.6446765 , 0.64468646, ..., 0.64553976, 0.64545035,
        0.64536095],
       [0.64668185, 0.64668685, 0.6466968 , ..., 0.647473  , 0.64738303,
        0.64728814],
       [0.6487047 , 0.6487097 , 0.6487197 , ..., 0.6494178 , 0.6493223 ,
        0.64923185],
       ...,
       [1.2261301 , 1.2270807 , 1.2280418 , ..., 0.7013282 , 0.6985367 ,
        0.6957644 ],
       [1.2260944 , 1.2270448 , 1.2280059 , ..., 0.7012579 , 0.6984669 ,
        0.69569516],
       [1.2260585 , 1.2270089 , 1.2279699 , ..., 0.70118755, 0.6983971 ,
        0.6956288 ]], dtype=float32)}, 'collided': False, 'new_position': [-0.14014077186584473, 0.8792873620986938, -2.519925832748413], 'new_rotation': [0.0, 0.9925718452933582, 0.0, 0.12165990272451267], 'timestamp': 1767143870.5912085, 'collision_data': {'num_contacts': 7}, 'raw_contacts': [{'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.040691062808036804, 0.8179675340652466, -2.4923834800720215], 'position_on_b': [-0.040691934525966644, 0.8176782131195068, -2.4923858642578125], 'normal': [0.0024184377398341894, 0.999997079372406, -0.0001627898745937273], 'distance': 0.0002893218188546598, 'normal_force': 0.0, 'friction_force1': 0.0, 'friction_force2': 0.0, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}, {'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.043434374034404755, 0.820004403591156, -2.481360673904419], 'position_on_b': [-0.0439734160900116, 0.816601574420929, -2.480748176574707], 'normal': [0.15404540300369263, 0.9724394679069519, -0.17501863837242126], 'distance': 0.003499280894175172, 'normal_force': 0.0, 'friction_force1': 0.0, 'friction_force2': 0.0, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}, {'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.02241397649049759, 0.8179675936698914, -2.4878344535827637], 'position_on_b': [-0.02241475135087967, 0.8176348209381104, -2.4878344535827637], 'normal': [0.002341515151783824, 0.9999971985816956, -0.0001743828906910494], 'distance': 0.00033277360489591956, 'normal_force': 0.0, 'friction_force1': 0.0, 'friction_force2': 0.0, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}, {'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.23611745238304138, 0.8179675936698914, -2.5410208702087402], 'position_on_b': [-0.23611706495285034, 0.8181390166282654, -2.5410208702087402], 'normal': [0.0022635022178292274, 0.9999973773956299, -8.081264240900055e-05], 'distance': -0.00017142338037956506, 'normal_force': 42.051710188388824, 'friction_force1': 0.09649309504311532, 'friction_force2': 0.003445172069405089, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}, {'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.2602105140686035, 0.8180747628211975, -2.545895576477051], 'position_on_b': [-0.2602100372314453, 0.8181977868080139, -2.545895576477051], 'normal': [0.0039456686936318874, 0.9999921917915344, 0.00025709063629619777], 'distance': -0.00012302490358706564, 'normal_force': 0.0, 'friction_force1': 0.0, 'friction_force2': 0.0, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}, {'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.11490827798843384, 0.8180841207504272, -2.650054454803467], 'position_on_b': [-0.11490892618894577, 0.8178317546844482, -2.650054454803467], 'normal': [0.002567848190665245, 0.9999967217445374, 0.0001569621090311557], 'distance': 0.00025236690999008715, 'normal_force': 0.0, 'friction_force1': 0.0, 'friction_force2': 0.0, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}, {'object_id_a': 1, 'object_id_b': 0, 'position_on_a': [-0.1761336326599121, 0.8183797597885132, -2.404050827026367], 'position_on_b': [-0.1774960458278656, 0.8149251937866211, -2.4035472869873047], 'normal': [0.36355650424957275, 0.9218352437019348, -0.13433685898780823], 'distance': 0.0037474988494068384, 'normal_force': 0.0, 'friction_force1': 0.0, 'friction_force2': 0.0, 'is_active': True, 'link_id_a': -1, 'link_id_b': -1}], 'filtered_contacts': []}
âœ… Storing SINGLE result for action_1767143870210_0
Storing result using store_action_result() for action_1767143870210_0 | All stored IDs: ['action_1767143870210_0']
Stored results for id : action_1767143870210_0
âœ… Action 'velocity_control' completed, result stored
ğŸ¯ HABITATSTORE: Pulling next action from queue
ğŸ“­ HABITATSTORE: Action queue is empty
DEBUG: about to write rgb frame
ğŸ” DEBUG: WAITING - No result yet
âœ… Retrieved result for action_1767143870210_0 using get_action_result() 
ğŸ” DEBUG: RESULT GOT: dict_keys(['action_id', 'status', 'action', 'obstacle_direction', 'obstacle_distance', 'observations', 'collided', 'new_position', 'new_rotation', 'timestamp', 'collision_data', 'raw_contacts', 'filtered_contacts'])
ğŸ” DEBUG: Processing result...
ğŸ” DEBUG: new_pos=[-0.14014077  0.87928736 -2.51992583]
ğŸ” DEBUG: raw_rot=[0.0, 0.9925718452933582, 0.0, 0.12165990272451267]
ğŸ” DEBUG: list quat=[0.         0.99257185 0.         0.1216599 ]
ğŸ” DEBUG: FINAL current_quat=[0.0, 0.9925718452933582, 0.0, 0.12165990272451267]
âœ… SINGLE TURN COMPLETE: was 50.9Â°
ğŸš€ DEBUG: FINAL - pos=[-0.14014077  0.87928736 -2.51992583], yaw=2.898
Target xyz : [-0.15094197  2.35249805 -2.47645044]
Current position : [-0.14014077  0.87928736 -2.51992583]
Delta vector calculated : [-0.0108012   1.47321069  0.04347539]
ğŸ“Š Step 0: Distance to target = 0.04m
ğŸ” [STUCK_DETECT] Starting detection with escape logic...
âš ï¸ [STUCK_DETECT] Not enough points: 2 < 30
âœ… REACHED TARGET! Distance: 0.04m
ğŸ“¥ HABITATSTORE: Pushing action 'velocity_control' to queue
ğŸ“¦ HABITATSTORE: Added metadata to action 'velocity_control'
âœ… HABITATSTORE: Action 'velocity_control' queued (ID: action_1767143870629_0)
ğŸ“Š HABITATSTORE: Queue size: 1
ğŸ›‘ STOP PUSHED (ID: action_1767143870629_0) - EXITING NAV LOOP
Eecution time: 0.45467042922973633
Result Dict : {'action': 'move_forward', 'success': True, 'execution_time': 0.45467042922973633, 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}, 'timestamp': 1767143870.62935, 'notes': 'Continuous navigation completed', 'collision_occurred': False, 'movement_verified': True, 'collision_count': 0, 'is_stuck': False}
ğŸ“‹ Continuous navigation result: success=True, steps=0, final_dist=0.00m
Continuous Navigation Result : {'action': 'move_forward', 'success': True, 'execution_time': 0.45467042922973633, 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}, 'timestamp': 1767143870.62935, 'notes': 'Continuous navigation completed', 'collision_occurred': False, 'movement_verified': True, 'collision_count': 0, 'is_stuck': False, 'observations': {}, 'continuous_nav': {'target_xyz': [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223], 'dist_remaining': 0.0, 'lin_vel': 0.0, 'ang_vel': 0.0, 'yaw_error_deg': 0.0, 'complete': True}}
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014077  0.87928736 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14        0.98967767 -2.52      ]
ğŸ”   last_processed_time: 1767143851.9836216
ğŸ”   skipped_frames: 2
ğŸ” MOTION CHECK: Current position = [-0.14014077  0.87928736 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.1104m, threshold: 0.2400m
ğŸ”   rotation: 0.3977rad, threshold: 0.1000rad
ğŸ”   time_delta: 18.65s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: âœ… Rotation exceeds threshold: 0.398rad > 0.100rad
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
ğŸ¯ BUFFER DEBUG: Frame ID requested: 1
ğŸ¯ BUFFER DEBUG: Result type: <class 'tuple'>
âœ… BUFFER DEBUG: Got frame_dict type: <class 'dict'>
âœ… BUFFER DEBUG: Got metadata type: <class 'dict'>
ğŸ¯ DEPTH SCALE CHECK: range=(562.0, 2366.0) dtype=uint16
âœ… ORB-SLAM: PROCESSED FRAME #2 (buffer ID: 1) - rotation_0.398rad > 0.100rad
   Current position: [-0.14014077  0.87928736 -2.5199258 ]
   Actual movement: 0.110m
ğŸ”„ CONVERTING: Depth appears to be in millimeters
   Before: 562.0 to 2366.0 (uint16)
   After: 0.562m to 2.366m (float32)
ğŸ” DEPTH VALIDATION: 307200 valid pixels
ğŸ” RGB-D Frames: RGB=(480, 640, 3), Depth=(480, 640)
ğŸ” Depth info: dtype=float32, range=(0.562, 2.366)
ğŸ” DEBUG process_frame parameters:
   RGB: dtype=uint8, shape=(480, 640, 3)
   Depth: dtype=float32, shape=(480, 640)
   Timestamp: 0.033
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ” ORB-SLAM RAW RESULT KEYS: ['current_pose', 'tracking_status', 'visible_points']
Current result dict pose : [[ 1.00000000e+00 -3.10459131e-10  3.68162723e-09  0.00000000e+00]
 [ 3.10459131e-10  1.00000000e+00  3.47504425e-09  0.00000000e+00]
 [-3.68162723e-09 -3.47504425e-09  1.00000000e+00  0.00000000e+00]
 [ 3.73947184e-09  2.72203260e-09  1.21563151e-08  1.00000000e+00]]
ğŸ” ORB-SLAM INTERNAL DEBUG:
   Raw tracking_info keys: ['tracking_ok', 'tracking_lost', 'system_shutdown', 'visible_points_count']
   ğŸ“ tracking_ok: True
   ğŸ“ tracking_lost: False
   ğŸ“ system_shutdown: False
   ğŸ¯ TRACKING STATUS: âœ… TRACKING
   ğŸ¯ LOST STATUS: âœ… NOT LOST
ğŸ” FEATURE DEBUG:
   ğŸ‘ï¸ Visible points: 843
ğŸ¤– ORB-SLAM: Received valid 4x4 pose matrix
â³ Coordinates from orbslam Not aligned yet, storing SLAM-local pose
ğŸ“¦ Stored pose pair #2
   SLAM position: [[ 1.00000000e+00 -3.10459131e-10  3.68162723e-09  0.00000000e+00]
 [ 3.10459131e-10  1.00000000e+00  3.47504425e-09  0.00000000e+00]
 [-3.68162723e-09 -3.47504425e-09  1.00000000e+00  0.00000000e+00]
 [ 3.73947184e-09  2.72203260e-09  1.21563151e-08  1.00000000e+00]]
   Habitat position: [[-0.97039768  0.          0.24151237 -0.14014077]
 [ 0.          1.          0.          0.87928736]
 [-0.24151237  0.         -0.97039768 -2.51992583]
 [ 0.          0.          0.          1.        ]]
ğŸ¯ STORE DEBUG - Frame 1:
   ğŸ“¦ Current pose type: <class 'numpy.ndarray'>
   ğŸ“¦ Pose shape: (4, 4)
   ğŸ“¦ Translation: [[ 1.00000000e+00 -3.10459131e-10  3.68162723e-09  0.00000000e+00]
 [ 3.10459131e-10  1.00000000e+00  3.47504425e-09  0.00000000e+00]
 [-3.68162723e-09 -3.47504425e-09  1.00000000e+00  0.00000000e+00]
 [ 3.73947184e-09  2.72203260e-09  1.21563151e-08  1.00000000e+00]]
ğŸ—ºï¸ ORB-SLAM: 843 tracked points this frame
âœ… ORB-SLAM: Pose stored successfully
ğŸ“¦ Stored complete 4x4 pose matrix for frame 1
ğŸ¤– ORB-SLAM: Complete pose stored directly
ğŸ” Point conversion: 843 success, 843 rich points
ğŸ’¾ ORB-SLAM: Added 843 points to memory map
   ğŸ¯ Current Frame: 1
   ğŸ¤– Robot Position: [[ 1.00000000e+00 -3.10459131e-10  3.68162723e-09  0.00000000e+00]
 [ 3.10459131e-10  1.00000000e+00  3.47504425e-09  0.00000000e+00]
 [-3.68162723e-09 -3.47504425e-09  1.00000000e+00  0.00000000e+00]
 [ 3.73947184e-09  2.72203260e-09  1.21563151e-08  1.00000000e+00]]
ğŸ’¾ ORB-SLAM: Frame 1 WORLD-ALIGNED data stored
ğŸ“Š ORB-SLAM FRAME 1 SUMMARY:
   Method: rgbd_processing
   Pose estimated: True
   Visible points: 843
   Tracking: OK
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¥ Agent-1 sensors: ['third_rgb']
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¥ Spectator frame saved: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005/spectator_view_before_1.png
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ’¡ Processing frame 1 brightness: 142.2
âœ… Frame 1 captured - RGB: (480, 640, 3), Depth: (480, 640)
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ” Mission check: 1 total goals, 1 remaining
   Mission goals: {'tv'}
   Remaining goals: ['tv']

--- FRAME 3/500 ---
DEBUG: about to get sensor observations
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¦‰ OWL: starting to Process REAL frame 1 
ğŸ¯ CURRENT SENSORS: ['rgba_camera', 'depth_camera']
DEBUG: about to extract rgb and depth
ğŸ¯ DEPTH STATS - Min: 0.6446715593338013, Max: 1.432079553604126, Mean: 1.072
âœ… Depth frame has 307200 valid pixels
DEBUG: RGBA -> RGB conversion for frame 2
DEBUG: Transposing rgb_frame from (640, 480, 3) to (480, 640, 3)
DEBUG: Depth frame shape before transpose: (640, 480)
DEBUG: Depth frame shape after transpose: (480, 640)
DEBUG: Converted depth dtype to uint16
DEBUG: about to rotate rgb frame
DEBUG: about to scale depth
ğŸ¯ DEBUG: Frame 2 - RGB shape: (480, 640, 3), Depth shape: (480, 640)
ğŸ¯ DEBUG: RGB dtype: uint8, Depth dtype: uint16
ğŸ¦‰ OWL: starting to Process REAL frame 1 
âœ… DEBUG: Frame 2 written to buffer - Slot 2
âœ… DEBUG: Buffer RGB dtype: uint8, Depth dtype: uint16
  Wrote frame 2 to buffer successfully âœ…
  âœ… Frame 3 captured - RGB: (480, 640, 3), Depth: (480, 640)
ğŸŸ¦ DEBUG: Calling ORB-SLAM process_frame() for frame 2
ğŸŸ© DEBUG: Returned from ORB-SLAM process_frame() for frame 2
ğŸ” Checking for queued actions...
ğŸ¯ HABITATSTORE: Pulling next action from queue
ğŸ›‘ STOP PRIORITY DETECTED at index 0: action_1767143870629_0
ğŸš€ HABITATSTORE: Pulled VELOCITY CONTROL command
   ğŸ“¦ Metadata: ['is_stop_command', 'target_reached', 'final_distance', 'continuous_nav', 'align_to_goal', 'target_xyz']
ğŸ“Š HABITATSTORE: Remaining in queue: 0
ğŸ¯ MAINORCH: Executing action 'velocity_control'
================================================================================
ğŸ¯ Executing Habitat action: velocity_control
ğŸ“¦ Parameters: {'linear_velocity': [0.0, 0.0, 0.0], 'angular_velocity': [0.0, 0.0, 0.0], 'duration': 0.1, 'is_velocity_command': True}
ğŸ“¦ Metadata: {'is_stop_command': True, 'target_reached': True, 'final_distance': 0.04479704597005918, 'continuous_nav': True, 'align_to_goal': True, 'target_xyz': [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]}
================================================================================
ğŸ›‘ EXECUTING ZERO-VELOCITY STOP + FACE GOAL
ğŸ¯ GOAL POSITION REACHED - Flag set!
ğŸ” DEBUG: LoCoBot pos=[-0.140, 0.879, -2.520]
âœ… LoCoBot STOPPED (zero velocity)
ğŸ¯ Goal=[-0.15094197  2.35249805 -2.47645044], LoCoBot=[-0.14014077  0.87928736 -2.51992583]
ğŸ“ Current yaw=166.0Â° â†’ Desired=-166.0Â° â†’ Error=27.9Â°
âœ… PHYSICS ALIGNMENT â†’ -166.0Â°
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” FINAL LoCoBot pos=[-0.140, 0.879, -2.520]
ğŸ” FINAL quat=[-0.0000, 0.9926, -0.0000, 0.1217]
ğŸ“¤ Result pos=[-0.14014048874378204, 0.8794272541999817]
ğŸ“¤ Result quat=[-2.41720163850212e-14, 0.9925718903541565, -1.9902227652371374e-13, 0.12165965884923935]
ğŸ›‘ PHYSICS STOP + ALIGNMENT COMPLETE âœ“
Action in habitat simulation result : {'action_id': 'action_1767143870629_0', 'status': 'completed', 'action': 'velocity_control', 'observations': {'rgba_camera': array([[[131, 121, 121, 255],
        [131, 121, 122, 255],
        [129, 119, 120, 255],
        ...,
        [128, 128, 120, 255],
        [128, 128, 120, 255],
        [128, 128, 120, 255]],

       [[131, 121, 120, 255],
        [129, 120, 119, 255],
        [127, 119, 118, 255],
        ...,
        [128, 128, 120, 255],
        [128, 128, 120, 255],
        [128, 128, 120, 255]],

       [[131, 121, 120, 255],
        [131, 121, 120, 255],
        [126, 119, 117, 255],
        ...,
        [128, 128, 120, 255],
        [128, 128, 120, 255],
        [128, 128, 120, 255]],

       ...,

       [[126, 110,  93, 255],
        [126, 110,  93, 255],
        [126, 110,  93, 255],
        ...,
        [167, 168, 167, 255],
        [167, 168, 167, 255],
        [167, 168, 167, 255]],

       [[126, 110,  93, 255],
        [126, 110,  93, 255],
        [124, 108,  91, 255],
        ...,
        [167, 168, 167, 255],
        [167, 168, 167, 255],
        [167, 168, 167, 255]],

       [[124, 108,  91, 255],
        [124, 108,  91, 255],
        [124, 108,  91, 255],
        ...,
        [167, 168, 167, 255],
        [167, 168, 167, 255],
        [167, 168, 167, 255]]], dtype=uint8), 'depth_camera': array([[0.6445651 , 0.64457005, 0.64457995, ..., 0.64543796, 0.64534855,
        0.6452592 ],
       [0.6465747 , 0.6465797 , 0.64658964, ..., 0.647368  , 0.64727813,
        0.64718825],
       [0.6485968 , 0.6486019 , 0.6486119 , ..., 0.64931226, 0.6492218 ,
        0.64913136],
       ...,
       [1.2261212 , 1.2270718 , 1.2280328 , ..., 0.7013282 , 0.6985396 ,
        0.69577014],
       [1.2260854 , 1.2270359 , 1.2279968 , ..., 0.7012579 , 0.6984698 ,
        0.69570094],
       [1.2260495 , 1.227     , 1.227961  , ..., 0.70118755, 0.6984    ,
        0.6956317 ]], dtype=float32)}, 'collided': False, 'new_position': [-0.14014048874378204, 0.8794272541999817, -2.519925832748413], 'new_rotation': [-2.41720163850212e-14, 0.9925718903541565, -1.9902227652371374e-13, 0.12165965884923935], 'timestamp': 1767143871.0497584, 'is_stop_result': True, 'stop_success': True, 'facing_goal_yaw': -2.8980790736182933}
âœ… Storing SINGLE result for action_1767143870629_0
Storing result using store_action_result() for action_1767143870629_0 | All stored IDs: ['action_1767143870629_0']
Stored results for id : action_1767143870629_0
âœ… Action 'velocity_control' completed, result stored
ğŸ¯ HABITATSTORE: Pulling next action from queue
ğŸ“­ HABITATSTORE: Action queue is empty
  ğŸ–¼ Frame 2 shape: (480, 640, 3)
  âœ… Frame orientation: PORTRAIT (480x640)
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014077  0.87928736 -2.5199258 ]
ğŸ”   last_processed_time: 1767143870.6335618
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0001m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 0.52s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â­ï¸ Skipping - trans=0.000m, rot=0.000rad, time=0.5s
ğŸ”   All below thresholds: trans<0.240, rot<0.100, time<1.0
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
  ğŸ–¼ Saved to: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005/ours_full_frame_2.png
  ğŸ–¼ Saved ours_full_frame_2.png
DEBUG: about to write rgb frame
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¥ Agent-1 sensors: ['third_rgb']
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¥ Spectator frame saved: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005/spectator_view_before_2.png
ğŸ’¡ Processing frame 2 brightness: 141.2
âœ… Frame 2 captured - RGB: (480, 640, 3), Depth: (480, 640)
ğŸ“Š Progress: 3/500 frames (0.6%)
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
âœ… Task completed: Unknown
âœ… Task completed successfully
Mission progress: 20.0%
âœ… Execution complete in background thread. Mission progress: 20.0%
execution results :  [{'action': 'move_forward', 'success': True, 'execution_time': 0.45467042922973633, 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}, 'timestamp': 1767143870.62935, 'notes': 'Continuous navigation completed', 'collision_occurred': False, 'movement_verified': True, 'collision_count': 0, 'is_stuck': False, 'observations': {}, 'continuous_nav': {'target_xyz': [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223], 'dist_remaining': 0.0, 'lin_vel': 0.0, 'ang_vel': 0.0, 'yaw_error_deg': 0.0, 'complete': True}}]
ğŸ“Š Checking 1 actions for status...
Fail to track local map!
âœ… Execution completed in run_execution_cycle: 1 actions executed
âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…
âœ… ACTION COMPLETED: '{'type': 'move_forward', 'action': 'move_forward', 'parameters': {'target_object': 'object1', 'search_pattern': 'pattern description', 'source': 'tree_of_thoughts', 'target_coordinates': None}}'
   â±ï¸  Execution time: 1.46s
   ğŸ“Š Result: execution_completed
   ğŸ¯ Total executed: 1
âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…âœ…
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014077  0.87928736 -2.5199258 ]
ğŸ”   last_processed_time: 1767143870.6335618
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0001m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 1.02s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 1.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'tuple'>
âœ… BUFFER DEBUG: Got frame_dict type: <class 'dict'>
âœ… BUFFER DEBUG: Got metadata type: <class 'dict'>
ğŸ¯ DEPTH SCALE CHECK: range=(644.0, 1432.0) dtype=uint16
âœ… ORB-SLAM: PROCESSED FRAME #3 (buffer ID: 2) - time_1.0s > 1.0s
   Current position: [-0.14014049  0.87942725 -2.5199258 ]
   Actual movement: 0.000m
ğŸ”„ CONVERTING: Depth appears to be in millimeters
   Before: 644.0 to 1432.0 (uint16)
   After: 0.644m to 1.432m (float32)
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEPTH VALIDATION: 307200 valid pixels
ğŸ” RGB-D Frames: RGB=(480, 640, 3), Depth=(480, 640)
ğŸ” Depth info: dtype=float32, range=(0.644, 1.432)
ğŸ” DEBUG process_frame parameters:
   RGB: dtype=uint8, shape=(480, 640, 3)
   Depth: dtype=float32, shape=(480, 640)
   Timestamp: 0.066
ğŸ¦‰ OWL: starting to Process REAL frame 2 

==================================================
ğŸ ORCHESTRATION COMPLETED
==================================================
ğŸ¯ Target frames: 500
âœ… Frames written to buffer: 3
âŒ Frames failed: 0
ğŸ“Š Total attempted: 3
ğŸ¯ Next frame ID (if continued): 3
â±ï¸  Total time: 19.88 seconds
ğŸ“ˆ Average FPS: 0.15

ğŸ”§ Buffer Statistics:
   Utilization: 4.7%
   Health Score: 100/100
   Active Readers: Not available
ğŸ” Mission check: 1 total goals, 1 remaining
   Mission goals: {'tv'}
   Remaining goals: ['tv']

ğŸ¯ Mission status: INCOMPLETE
==================================================
âœ… DEBUG: Orchestration completed!
ğŸ“ˆ DEBUG: Trajectory extracted, len = 2
ğŸ’¥ DEBUG: Collisions extracted = 0
ğŸ“Š DEBUG: Computing final metrics...
ğŸ DEBUG: Final pos = [-0.14014077  0.87928736 -2.51992583]
ğŸ“ DEBUG: Final distance = 1.474m
âœ… DEBUG: Success = 0 (threshold 0.2m)
ğŸ“Š Filtered 2 â†’ 2 points
ğŸ›¤ï¸ 2D XZ Path length = 0.000m (2 points)
ğŸ“ DEBUG: SPL = 0.0 (no success or short trajectory)
ğŸ”¥ DEBUG: Failure mode = 'distance'
ğŸ“‹ DEBUG: Final metrics = {'success': 0, 'spl': 0.0, 'path_length': 0.00015910531957246437, 'collisions': 0, 'final_distance': 1.4738916240843922, 'failure_mode': 'distance', 'trajectory': [array([-0.14,  1.  , -2.52], dtype=float32), array([-0.14014077,  0.87928736, -2.51992583])]}
ğŸ” DEBUG: About to plot trajectory...
   Trajectory length: 2
   Start pos: [-0.14  1.   -2.52]
   Final pos: [-0.14014077  0.87928736 -2.51992583]
   Goal pos: [-0.15094196796417236, 2.3524980545043945, -2.4764504432678223]
   Frame dir: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005
   Final distance: 1.474m
ğŸ” ORB-SLAM RAW RESULT KEYS: ['current_pose', 'tracking_status', 'visible_points']
Current result dict pose : [[ 9.99982953e-01  4.78829909e-03 -3.33979493e-03  0.00000000e+00]
 [-5.81249967e-03  7.63210297e-01 -6.46124065e-01  0.00000000e+00]
 [-5.44868992e-04  6.46132410e-01  7.63225138e-01  0.00000000e+00]
 [-8.55544731e-02 -5.22057772e-01  8.66513848e-02  1.00000000e+00]]
ğŸ” ORB-SLAM INTERNAL DEBUG:
   Raw tracking_info keys: ['tracking_ok', 'tracking_lost', 'system_shutdown', 'visible_points_count']
   ğŸ“ tracking_ok: False
   ğŸ“ tracking_lost: False
   ğŸ“ system_shutdown: False
   ğŸ¯ TRACKING STATUS: âŒ NOT TRACKING
   ğŸ¯ LOST STATUS: âœ… NOT LOST
ğŸ” FEATURE DEBUG:
   ğŸ‘ï¸ Visible points: 7
ğŸ¤– ORB-SLAM: Received valid 4x4 pose matrix
â³ Coordinates from orbslam Not aligned yet, storing SLAM-local pose
ğŸ¯ STORE DEBUG - Frame 2:
   ğŸ“¦ Current pose type: <class 'numpy.ndarray'>
   ğŸ“¦ Pose shape: (4, 4)
   ğŸ“¦ Translation: [[ 9.99982953e-01  4.78829909e-03 -3.33979493e-03  0.00000000e+00]
 [-5.81249967e-03  7.63210297e-01 -6.46124065e-01  0.00000000e+00]
 [-5.44868992e-04  6.46132410e-01  7.63225138e-01  0.00000000e+00]
 [-8.55544731e-02 -5.22057772e-01  8.66513848e-02  1.00000000e+00]]
ğŸ—ºï¸ ORB-SLAM: 7 tracked points this frame
âœ… ORB-SLAM: Pose stored successfully
ğŸš« ORB-SLAM: SKIPPING position - invalid tracking
   Reason: tracking_ok = False
   Reason: visible_points = 7 (need > 50)
ğŸ” Point conversion: 7 success, 7 rich points
ğŸ’¾ ORB-SLAM: Added 7 points to memory map
   ğŸ¯ Current Frame: 2
   ğŸ¤– Robot Position: [[ 9.99982953e-01  4.78829909e-03 -3.33979493e-03  0.00000000e+00]
 [-5.81249967e-03  7.63210297e-01 -6.46124065e-01  0.00000000e+00]
 [-5.44868992e-04  6.46132410e-01  7.63225138e-01  0.00000000e+00]
 [-8.55544731e-02 -5.22057772e-01  8.66513848e-02  1.00000000e+00]]
ğŸ’¾ ORB-SLAM: Frame 2 WORLD-ALIGNED data stored
ğŸ“Š ORB-SLAM FRAME 2 SUMMARY:
   Method: rgbd_processing
   Pose estimated: True
   Visible points: 7
   Tracking: FAILED
âœ… frame_dir exists: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005
ğŸ¨ Generating visualization results in: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 0
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 0.53s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â­ï¸ Skipping - trans=0.000m, rot=0.000rad, time=0.5s
ğŸ”   All below thresholds: trans<0.240, rot<0.100, time<1.0
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ“ˆ Trajectory plot saved: /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/experiments/paper_experiments/Main_Experiments/results/ours_full/00800_tv_005/trajectory_plot.png
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 1.03s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 1.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 1.57s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 1.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 2.07s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 2.1s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 2.61s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 2.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 3.15s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 3.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 3.66s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 3.7s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 4.18s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 4.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 4.72s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 4.7s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 5.25s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 5.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 5.76s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 5.8s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 6.29s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 6.3s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 6.79s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 6.8s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 7.34s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 7.3s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 7.86s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 7.9s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 8.41s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 8.4s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 8.91s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 8.9s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 9.45s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 9.5s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 9.99s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 10.0s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 10.52s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 10.5s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 11.06s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 11.1s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 11.58s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 11.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 12.12s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 12.1s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 12.62s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 12.6s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 13.16s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 13.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 13.70s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 13.7s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 14.24s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 14.2s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 14.78s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 14.8s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¯ HABITAT ACTUAL POSITION: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CHECK DEBUG: Starting motion check
ğŸ”   last_processed_position: [-0.14014049  0.87942725 -2.5199258 ]
ğŸ”   last_processed_time: 1767143871.6523616
ğŸ”   skipped_frames: 1
ğŸ” MOTION CHECK: Current position = [-0.14014049  0.87942725 -2.5199258 ]
ğŸ” MOTION CALCULATIONS:
ğŸ”   translation: 0.0000m, threshold: 0.2400m
ğŸ”   rotation: 0.0000rad, threshold: 0.1000rad
ğŸ”   time_delta: 15.44s, threshold: 1.0s
ğŸ”   motion_stats: avg_trans=0.300, avg_rot=0.100
ğŸ” MOTION CHECK: â° Time threshold exceeded: 15.4s > 1.0s
ğŸ” DEBUG: This is FrameBuffer version WITH FILENAME SUPPORT
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ” DEBUG: stack[1].function = process_frame
ğŸ” DEBUG: stack[1].filename = /mnt/d/Coding/Business/Kulfi_Startup_Code/robotics_workspace/projects/hybrid_zero_shot_slam_nav/main/src/perception_pipeline/orb_slam_integration.py
ğŸ” DEBUG: type of filename = <class 'str'>
ğŸ” FRAMEBUFFER DEBUG: Caller function='process_frame [orb_slam_integration.py]', Model='orb_slam'
âš ï¸  Skipping frame 2 for orb_slam (already processed)
ğŸ¯ BUFFER DEBUG: Frame ID requested: 2
ğŸ¯ BUFFER DEBUG: Result type: <class 'NoneType'>
ğŸš¨ CRITICAL: Buffer returned None!
   This means ORB-SLAM will get NO FRAMES!
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
âœ… plot_trajectory() call completed
âœ… Both files saved, shutting down...
ğŸ›‘ Shutting down main orchestration...
ğŸ”š Shutting down run_action_pipeline execution...
Action Executor shutdown complete
ğŸ’¾ Saving final predictions to disk...
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ”š Shutting down event-driven execution...
ğŸ”š Shutting down run_action_pipeline execution...
Action Executor shutdown complete
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ’¾ 1 predictions saved to experiments/results/predictions/final_predictions.json
âœ… Final predictions saved to: experiments/results/predictions/final_predictions.json
Tree of Thoughts shutdown
Integrated reasoning pipeline shutdown complete
Shutting down ORB-SLAM3 integration...
ğŸ¦‰ OWL: starting to Process REAL frame 2 
ğŸ¦‰ OWL: starting to Process REAL frame 2 
âŒ TRAJECTORY FAILED: experiments/results/trajectory/all_frames.tum
âŒ KEYFRAMES FAILED: experiments/results/trajectory/keyframes.tum
Shutting down OWL integration...
ğŸ›‘ Stopping OWL thread...
ğŸ›‘ OWL continuous processing loop stopped
â±ï¸  OWL TOTAL STATS:
   ğŸ“Š Frames processed: 1
   â° Total wall time: 37.21s
   ğŸ”„ Total processing time: 2.29s
   ğŸ“ˆ Average FPS: 0.03
   âš¡ Processing efficiency: 6.2%
ğŸ›‘ OWL: Stopped continuous processing
OWL performance stats: {'total_frames_processed': 1, 'avg_processing_time': 2.289564609527588, 'max_processing_time': 2.289564609527588, 'min_processing_time': 2.289564609527588, 'current_objects_count': 0, 'last_processed_frame': -1, 'text_queries_count': 100, 'total_processing_time': 2.289564609527588, 'batch_size': 2, 'batch_efficiency': 1.144782304763794}
OWL integration shutdown complete
ğŸ›‘ HabitatStore shutdown complete
ğŸ§¹ Shutting down DEADLOCK-FREE Frame Buffer...
âœ… Shared memory released
ğŸ¯ DEADLOCK-FREE Buffer shutdown complete
ğŸ”„ MapStore shutdown - saving final map...
ğŸ“ Found ORB-SLAM map: projects/hybrid_zero_shot_slam_nav/main/experiments/results/logs/orbslam_map.json
âœ… Using camera parameters from MapStore cache
ğŸ’¾ NPZ saved: experiments/results/final_maps/orb_slam_map_20251231_011807.npz
âœ… MapStore shutdown complete. Maps saved:
   ğŸ“ Complete: experiments/results/final_maps/orb_slam_map_20251231_011807.json
ğŸ—ºï¸ FINAL MAP SAVED: experiments/results/final_maps/orb_slam_map_20251231_011807.json
âœ… DEBUG: Shutdown complete!
ğŸ† DEBUG: Returning metrics to runner!
[DEBUG] Logging results | policy=ours_full | episode=00800_tv_005
[DEBUG] Appended row to existing CSV
âœ… Logged ours_full: success=0, SPL=0.000
[DEBUG] Saving failure data | policy=ours_full | episode=00800_tv_005
âŒ ours_full FAILED | error=[Errno 2] No such file or directory: 'logs/failures'
